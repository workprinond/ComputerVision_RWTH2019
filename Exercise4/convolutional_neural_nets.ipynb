{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "In this exercise you will be introduced to some practical aspects of deep learning in\n",
    "computer vision, including constructing a deep neural network and training it via gradient\n",
    "descent to tackle image classification.\n",
    "\n",
    "We will use the popular TensorFlow framework through the Keras API.\n",
    "\n",
    "## Install TensorFlow\n",
    "\n",
    "TensorFlow 2.0 will be released soon, but its beta version is already available. Install it using `pip install tensorflow==2.0.0-beta1` or if you have an Nvidia GPU, use  `pip install tensorflow-gpu==2.0.0-beta1`.\n",
    "\n",
    "GPUs make the training many times faster, but since not all of you have an Nvidia GPU available, we have tried to scale the exercise with a CPU in mind.\n",
    "\n",
    "## TensorBoard Plotting\n",
    "\n",
    "TensorBoard is a web-based tool for drawing pretty plots of quantities we care about during training, such as the loss. We need to choose a folder where these values will be stored (\"logdir\").\n",
    "\n",
    "Start the TensorBoard server by executing e.g. `tensorboard --logdir /tmp/tensorboard_logs` after you've activated your conda environment. If you change the logdir, also adjust it in the cell below.\n",
    "\n",
    "You can view the graphs by visiting http://localhost:6006 in your browser (6006 is the default port).\n",
    "At first there will be nothing to plot, so it will be empty. You can also open it afterwards in a separate browser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_root= '/work2/sarandi/temp/tensorboard_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import cv2\n",
    "from attrdict import AttrDict\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "import tensorflow.keras.initializers as initializers\n",
    "import tensorflow.keras.preprocessing.image as kerasimage\n",
    "tfk = tf.keras\n",
    "K = tfk.backend\n",
    "\n",
    "def plot_multiple(images, titles=None, colormap='gray',\n",
    "                  max_columns=np.inf, imwidth=4, imheight=4, share_axes=False):\n",
    "    \"\"\"Plot multiple images as subplots on a grid.\"\"\"\n",
    "    if titles is None:\n",
    "        titles = [''] *len(images)\n",
    "    assert len(images) == len(titles)\n",
    "    n_images = len(images)\n",
    "    n_cols = min(max_columns, n_images)\n",
    "    n_rows = int(np.ceil(n_images / n_cols))\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, n_cols, figsize=(n_cols * imwidth, n_rows * imheight),\n",
    "        squeeze=False, sharex=share_axes, sharey=share_axes)\n",
    "\n",
    "    axes = axes.flat\n",
    "    # Hide subplots without content\n",
    "    for ax in axes[n_images:]:\n",
    "        ax.axis('off')\n",
    "        \n",
    "    if not isinstance(colormap, (list,tuple)):\n",
    "        colormaps = [colormap]*n_images\n",
    "    else:\n",
    "        colormaps = colormap\n",
    "\n",
    "    for ax, image, title, cmap in zip(axes, images, titles, colormaps):\n",
    "        ax.imshow(image, cmap=cmap)\n",
    "        ax.set_title(title)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We are going to tackle the classic image classification task using the **CIFAR-10 dataset**, containing 60,000 32x32 RGB images of 10 different classes (10,000 for training and 10,000 for testing). \n",
    "\n",
    "![image.png](cifar.png)\n",
    "\n",
    "The dataset is automatically downloaded if you run the next cell.\n",
    "You may read more about the dataset at https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\n",
    "A common normalization strategy is to map the image RGB values to the range 0-1 and subtract the mean pixel value across the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.datasets.cifar10\n",
    "(im_train, y_train),(im_test, y_test) = dataset.load_data()\n",
    "# Normalize to 0-1 range and subtract mean of training pixels\n",
    "im_train = im_train / 255\n",
    "im_test = im_test / 255\n",
    "\n",
    "mean_training_pixel = np.mean(im_train, axis=(0,1,2))\n",
    "x_train = im_train - mean_training_pixel\n",
    "x_test = im_test - mean_training_pixel\n",
    "\n",
    "image_shape = x_train[0].shape\n",
    "labels = ['airplane','automobile','bird','cat',\n",
    "          'deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by Softmax Regression\n",
    "\n",
    "Before considering convolutional neural networks, let us start with a simpler classifier called softmax regression (a.k.a. multinomial logistic regression). Note that even though the name contains \"regression\", this is a classification model.\n",
    "\n",
    "It can be understood as a single-layer neural network. We first flatten our input image to a long vector $\\mathbf{x}$, consisting of $32\\cdot 32\\cdot 3= 3072$ values. Then we predict class probabilities $\\hat{\\mathbf{y}}$ using a linear layer with softmax activation:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = W \\mathbf{x} + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y}_c = \\operatorname{softmax}(\\mathbf{z})_c = \\frac{\\exp{z_c}}{\\sum_{\\tilde{c}=1}^{10} \\exp{z_{\\tilde{c}}}}\n",
    "$$\n",
    "\n",
    "Here $z_c$ denotes the $c$th component of the vector $\\mathbf{z}$, called the vector of **logits**. \n",
    "The weights $W$ and biases $\\mathbf{b}$ will be learned during training.\n",
    "\n",
    "## Training\n",
    "\n",
    "We train the model by minimizing a **loss function** averaged over the training data. As we are tackling a classification problem, the **cross-entropy** is the suitable loss function:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{CE}(\\mathbf{y}, \\hat{\\mathbf{y}}; W, \\mathbf{b}) = - \\sum_{c=1}^{10} y_c \\log{\\hat{y}_c}\n",
    "$$\n",
    "\n",
    "Note that in the above notation the ground-truth $\\mathbf{y}$ is a so-called **one-hot vector**, containing a single 1 while the remaining components \n",
    "are zeros. Conversely, $\\hat{\\mathbf{y}}$ is a vector which sums to one, but where all components take continuous values in $(0, 1)$. What is the intuition behind this loss function?\n",
    "\n",
    "We minimize the loss by **stochastic gradient descent** (SGD). That is, we repeatedly sample mini-batches from the training data and update the parameters (weights and biases) towards the direction of the steepest decrease of the loss averaged over the mini-batch. For example, the weight $w_{ij}$ (an element of the matrix $W$) is updated according to:\n",
    "\n",
    "$$\n",
    "w_{ij}^{(t+1)} = w_{ij}^{(t)} - \\eta \\cdot \\frac{\\partial \\mathcal{L}_{CE}} {\\partial w_{ij}},\n",
    "$$\n",
    "\n",
    "with $\\eta$ being the learning rate.\n",
    "\n",
    "----\n",
    "\n",
    "This is all very simple to perform in Keras. `models.Sequential` accepts a list of layers that are applied sequentially, in a chain. Here we have two layers, `Flatten` to convert the image into a long vector and `Dense`, which is a fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_regression = models.Sequential([\n",
    "    layers.Flatten(input_shape=image_shape),\n",
    "    layers.Dense(10, activation='softmax')],\n",
    "    name='linear')\n",
    "\n",
    "def train_model(model, batch_size=128, n_epochs=100, optimizer=optimizers.SGD,\n",
    "                learning_rate=1e-2):\n",
    "    opt = optimizer(lr=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=opt, loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    logdir = os.path.join(log_root, f'{model.name}_{timestamp}')\n",
    "    tensorboard_callback = callbacks.TensorBoard(logdir, profile_batch=0)\n",
    "    model.fit(x=x_train, y=y_train, verbose=1, epochs=n_epochs, \n",
    "              validation_data=(x_test, y_test), batch_size=batch_size,\n",
    "              callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0624 02:25:44.771519 139635184215872 deprecation.py:323] From /home/sarandi/anaconda3/envs/ml-tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 2s 39us/sample - loss: 1.9937 - accuracy: 0.3016 - val_loss: 1.8912 - val_accuracy: 0.3506\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.8627 - accuracy: 0.3628 - val_loss: 1.8368 - val_accuracy: 0.3674\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.8211 - accuracy: 0.3774 - val_loss: 1.8099 - val_accuracy: 0.3795\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7965 - accuracy: 0.3860 - val_loss: 1.7904 - val_accuracy: 0.3840\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7792 - accuracy: 0.3922 - val_loss: 1.7757 - val_accuracy: 0.3913\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7663 - accuracy: 0.3974 - val_loss: 1.7665 - val_accuracy: 0.3951\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7559 - accuracy: 0.4018 - val_loss: 1.7587 - val_accuracy: 0.3953\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7472 - accuracy: 0.4038 - val_loss: 1.7538 - val_accuracy: 0.3979\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7402 - accuracy: 0.4070 - val_loss: 1.7484 - val_accuracy: 0.3987\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7337 - accuracy: 0.4084 - val_loss: 1.7421 - val_accuracy: 0.4043\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7284 - accuracy: 0.4112 - val_loss: 1.7385 - val_accuracy: 0.4057\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7237 - accuracy: 0.4128 - val_loss: 1.7361 - val_accuracy: 0.4007\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7196 - accuracy: 0.4148 - val_loss: 1.7316 - val_accuracy: 0.4063\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7155 - accuracy: 0.4146 - val_loss: 1.7317 - val_accuracy: 0.4062\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.7118 - accuracy: 0.4171 - val_loss: 1.7271 - val_accuracy: 0.4097\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.7085 - accuracy: 0.4189 - val_loss: 1.7261 - val_accuracy: 0.4084\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7058 - accuracy: 0.4185 - val_loss: 1.7245 - val_accuracy: 0.4094\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7032 - accuracy: 0.4197 - val_loss: 1.7217 - val_accuracy: 0.4106\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.7006 - accuracy: 0.4213 - val_loss: 1.7211 - val_accuracy: 0.4113\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6984 - accuracy: 0.4218 - val_loss: 1.7181 - val_accuracy: 0.4113\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6960 - accuracy: 0.4226 - val_loss: 1.7183 - val_accuracy: 0.4099\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6939 - accuracy: 0.4227 - val_loss: 1.7167 - val_accuracy: 0.4124\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6922 - accuracy: 0.4254 - val_loss: 1.7167 - val_accuracy: 0.4121\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6898 - accuracy: 0.4266 - val_loss: 1.7150 - val_accuracy: 0.4124\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6884 - accuracy: 0.4262 - val_loss: 1.7137 - val_accuracy: 0.4104\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6867 - accuracy: 0.4269 - val_loss: 1.7151 - val_accuracy: 0.4114\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6851 - accuracy: 0.4281 - val_loss: 1.7132 - val_accuracy: 0.4119\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6836 - accuracy: 0.4285 - val_loss: 1.7126 - val_accuracy: 0.4116\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.6821 - accuracy: 0.4282 - val_loss: 1.7123 - val_accuracy: 0.4083\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6808 - accuracy: 0.4285 - val_loss: 1.7108 - val_accuracy: 0.4124\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6794 - accuracy: 0.4304 - val_loss: 1.7108 - val_accuracy: 0.4111\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6781 - accuracy: 0.4314 - val_loss: 1.7098 - val_accuracy: 0.4112\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6767 - accuracy: 0.4301 - val_loss: 1.7107 - val_accuracy: 0.4117\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.6756 - accuracy: 0.4322 - val_loss: 1.7098 - val_accuracy: 0.4125\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6746 - accuracy: 0.4321 - val_loss: 1.7092 - val_accuracy: 0.4111\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.6734 - accuracy: 0.4318 - val_loss: 1.7089 - val_accuracy: 0.4149\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.6724 - accuracy: 0.4329 - val_loss: 1.7076 - val_accuracy: 0.4129\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6713 - accuracy: 0.4325 - val_loss: 1.7075 - val_accuracy: 0.4116\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6704 - accuracy: 0.4342 - val_loss: 1.7072 - val_accuracy: 0.4106\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6691 - accuracy: 0.4342 - val_loss: 1.7090 - val_accuracy: 0.4126\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6684 - accuracy: 0.4355 - val_loss: 1.7076 - val_accuracy: 0.4134\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6676 - accuracy: 0.4340 - val_loss: 1.7067 - val_accuracy: 0.4115\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6666 - accuracy: 0.4360 - val_loss: 1.7062 - val_accuracy: 0.4126\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6656 - accuracy: 0.4364 - val_loss: 1.7060 - val_accuracy: 0.4126\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6649 - accuracy: 0.4363 - val_loss: 1.7079 - val_accuracy: 0.4116\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6642 - accuracy: 0.4358 - val_loss: 1.7063 - val_accuracy: 0.4113\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6632 - accuracy: 0.4367 - val_loss: 1.7053 - val_accuracy: 0.4143\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6623 - accuracy: 0.4377 - val_loss: 1.7043 - val_accuracy: 0.4134\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6619 - accuracy: 0.4376 - val_loss: 1.7065 - val_accuracy: 0.4129\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6611 - accuracy: 0.4367 - val_loss: 1.7046 - val_accuracy: 0.4112\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6602 - accuracy: 0.4375 - val_loss: 1.7057 - val_accuracy: 0.4131\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6592 - accuracy: 0.4388 - val_loss: 1.7054 - val_accuracy: 0.4120\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6587 - accuracy: 0.4387 - val_loss: 1.7038 - val_accuracy: 0.4131\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6582 - accuracy: 0.4390 - val_loss: 1.7055 - val_accuracy: 0.4130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6574 - accuracy: 0.4388 - val_loss: 1.7039 - val_accuracy: 0.4115\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6567 - accuracy: 0.4395 - val_loss: 1.7040 - val_accuracy: 0.4140\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6561 - accuracy: 0.4408 - val_loss: 1.7054 - val_accuracy: 0.4122\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6556 - accuracy: 0.4400 - val_loss: 1.7042 - val_accuracy: 0.4114\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6550 - accuracy: 0.4409 - val_loss: 1.7046 - val_accuracy: 0.4142\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6541 - accuracy: 0.4405 - val_loss: 1.7040 - val_accuracy: 0.4121\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6536 - accuracy: 0.4414 - val_loss: 1.7044 - val_accuracy: 0.4115\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6533 - accuracy: 0.4414 - val_loss: 1.7040 - val_accuracy: 0.4118\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6526 - accuracy: 0.4424 - val_loss: 1.7048 - val_accuracy: 0.4114\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6519 - accuracy: 0.4415 - val_loss: 1.7040 - val_accuracy: 0.4141\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.6514 - accuracy: 0.4426 - val_loss: 1.7045 - val_accuracy: 0.4127\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6510 - accuracy: 0.4425 - val_loss: 1.7047 - val_accuracy: 0.4117\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6504 - accuracy: 0.4409 - val_loss: 1.7046 - val_accuracy: 0.4147\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6499 - accuracy: 0.4429 - val_loss: 1.7039 - val_accuracy: 0.4122\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6494 - accuracy: 0.4428 - val_loss: 1.7045 - val_accuracy: 0.4133\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6487 - accuracy: 0.4436 - val_loss: 1.7054 - val_accuracy: 0.4129\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6484 - accuracy: 0.4425 - val_loss: 1.7036 - val_accuracy: 0.4125\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6476 - accuracy: 0.4441 - val_loss: 1.7064 - val_accuracy: 0.4118\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6475 - accuracy: 0.4440 - val_loss: 1.7045 - val_accuracy: 0.4131\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6467 - accuracy: 0.4434 - val_loss: 1.7036 - val_accuracy: 0.4163\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6466 - accuracy: 0.4451 - val_loss: 1.7033 - val_accuracy: 0.4150\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6460 - accuracy: 0.4443 - val_loss: 1.7042 - val_accuracy: 0.4139\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6455 - accuracy: 0.4452 - val_loss: 1.7058 - val_accuracy: 0.4108\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6450 - accuracy: 0.4450 - val_loss: 1.7031 - val_accuracy: 0.4142\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6448 - accuracy: 0.4453 - val_loss: 1.7040 - val_accuracy: 0.4115\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6440 - accuracy: 0.4453 - val_loss: 1.7042 - val_accuracy: 0.4132\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6438 - accuracy: 0.4458 - val_loss: 1.7040 - val_accuracy: 0.4135\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6435 - accuracy: 0.4451 - val_loss: 1.7048 - val_accuracy: 0.4130\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6430 - accuracy: 0.4448 - val_loss: 1.7044 - val_accuracy: 0.4129\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6425 - accuracy: 0.4450 - val_loss: 1.7035 - val_accuracy: 0.4158\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6421 - accuracy: 0.4465 - val_loss: 1.7047 - val_accuracy: 0.4163\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6417 - accuracy: 0.4459 - val_loss: 1.7063 - val_accuracy: 0.4126\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6413 - accuracy: 0.4458 - val_loss: 1.7057 - val_accuracy: 0.4127\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6410 - accuracy: 0.4456 - val_loss: 1.7036 - val_accuracy: 0.4136\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6406 - accuracy: 0.4458 - val_loss: 1.7044 - val_accuracy: 0.4122\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6403 - accuracy: 0.4473 - val_loss: 1.7044 - val_accuracy: 0.4139\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6399 - accuracy: 0.4468 - val_loss: 1.7046 - val_accuracy: 0.4114\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6393 - accuracy: 0.4462 - val_loss: 1.7052 - val_accuracy: 0.4137\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6392 - accuracy: 0.4459 - val_loss: 1.7050 - val_accuracy: 0.4128\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6388 - accuracy: 0.4474 - val_loss: 1.7065 - val_accuracy: 0.4135\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6383 - accuracy: 0.4469 - val_loss: 1.7048 - val_accuracy: 0.4136\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6381 - accuracy: 0.4471 - val_loss: 1.7034 - val_accuracy: 0.4156\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6375 - accuracy: 0.4483 - val_loss: 1.7052 - val_accuracy: 0.4137\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6372 - accuracy: 0.4485 - val_loss: 1.7058 - val_accuracy: 0.4151\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6370 - accuracy: 0.4476 - val_loss: 1.7045 - val_accuracy: 0.4151\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6367 - accuracy: 0.4475 - val_loss: 1.7059 - val_accuracy: 0.4136\n"
     ]
    }
   ],
   "source": [
    "train_model(softmax_regression, optimizer=optimizers.SGD, learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Jupyter Notebook Tip: After you're done training, you can collapse or hide the output by clicking or double clicking the area directly to the left of the output.)\n",
    "\n",
    "You can check the how the loss and accuracy change over the course of trainng in TensorBoard.\n",
    "\n",
    "What would be the cross-entropy loss for a dummy classifier that always outputs equal probabilities for all the classes? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimizer\n",
    "\n",
    "There has been a lot of research on improving on the simple stochastic gradient descent algorithm. One of the most popular variants is called **Adam** (https://arxiv.org/abs/1412.6980, \"adaptive moment estimation\"). Its learning rate usually requires less precise tuning, and something in the range of $(10^{-4},10^{-3})$ often works well in practice. This is because the algorithm automatically adapts the learning rate for each weight depending on the gradients.\n",
    "\n",
    "You can run it as follows (the optimizer is passed to Keras's `model.fit` function in `train_model`). The difference is not large for such a simple model, but makes a bigger difference for larger networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.9348 - accuracy: 0.3364 - val_loss: 1.8485 - val_accuracy: 0.3763\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.8249 - accuracy: 0.3865 - val_loss: 1.8096 - val_accuracy: 0.3922\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7933 - accuracy: 0.3980 - val_loss: 1.7897 - val_accuracy: 0.3947\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7741 - accuracy: 0.4045 - val_loss: 1.7747 - val_accuracy: 0.4031\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7599 - accuracy: 0.4105 - val_loss: 1.7651 - val_accuracy: 0.4047\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7497 - accuracy: 0.4144 - val_loss: 1.7593 - val_accuracy: 0.4058\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7410 - accuracy: 0.4181 - val_loss: 1.7565 - val_accuracy: 0.4055\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.7346 - accuracy: 0.4206 - val_loss: 1.7539 - val_accuracy: 0.4080\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.7292 - accuracy: 0.4230 - val_loss: 1.7540 - val_accuracy: 0.4078\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.7243 - accuracy: 0.4238 - val_loss: 1.7476 - val_accuracy: 0.4040\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7198 - accuracy: 0.4260 - val_loss: 1.7476 - val_accuracy: 0.4071\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7165 - accuracy: 0.4283 - val_loss: 1.7425 - val_accuracy: 0.4086\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7138 - accuracy: 0.4292 - val_loss: 1.7446 - val_accuracy: 0.4104\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7110 - accuracy: 0.4296 - val_loss: 1.7385 - val_accuracy: 0.4102\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7085 - accuracy: 0.4324 - val_loss: 1.7402 - val_accuracy: 0.4096\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.7068 - accuracy: 0.4313 - val_loss: 1.7394 - val_accuracy: 0.4138\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7047 - accuracy: 0.4324 - val_loss: 1.7397 - val_accuracy: 0.4051\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7039 - accuracy: 0.4329 - val_loss: 1.7377 - val_accuracy: 0.4130\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7018 - accuracy: 0.4348 - val_loss: 1.7400 - val_accuracy: 0.4082\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.7004 - accuracy: 0.4343 - val_loss: 1.7434 - val_accuracy: 0.4076\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.7002 - accuracy: 0.4328 - val_loss: 1.7379 - val_accuracy: 0.4145\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6986 - accuracy: 0.4358 - val_loss: 1.7375 - val_accuracy: 0.4116\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6980 - accuracy: 0.4358 - val_loss: 1.7407 - val_accuracy: 0.4107\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6967 - accuracy: 0.4346 - val_loss: 1.7364 - val_accuracy: 0.4102\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6961 - accuracy: 0.4360 - val_loss: 1.7361 - val_accuracy: 0.4129\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6954 - accuracy: 0.4364 - val_loss: 1.7389 - val_accuracy: 0.4112\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6948 - accuracy: 0.4362 - val_loss: 1.7371 - val_accuracy: 0.4127\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6936 - accuracy: 0.4366 - val_loss: 1.7394 - val_accuracy: 0.4121\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6938 - accuracy: 0.4384 - val_loss: 1.7393 - val_accuracy: 0.4106\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6934 - accuracy: 0.4376 - val_loss: 1.7393 - val_accuracy: 0.4134\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6920 - accuracy: 0.4391 - val_loss: 1.7409 - val_accuracy: 0.4094\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6921 - accuracy: 0.4390 - val_loss: 1.7404 - val_accuracy: 0.4128\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6916 - accuracy: 0.4383 - val_loss: 1.7397 - val_accuracy: 0.4115\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6914 - accuracy: 0.4385 - val_loss: 1.7391 - val_accuracy: 0.4127\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6907 - accuracy: 0.4411 - val_loss: 1.7433 - val_accuracy: 0.4129\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6908 - accuracy: 0.4391 - val_loss: 1.7410 - val_accuracy: 0.4103\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6901 - accuracy: 0.4389 - val_loss: 1.7400 - val_accuracy: 0.4131\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.6898 - accuracy: 0.4402 - val_loss: 1.7410 - val_accuracy: 0.4133\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6895 - accuracy: 0.4397 - val_loss: 1.7412 - val_accuracy: 0.4120\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6896 - accuracy: 0.4397 - val_loss: 1.7429 - val_accuracy: 0.4097\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6892 - accuracy: 0.4411 - val_loss: 1.7416 - val_accuracy: 0.4145\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6892 - accuracy: 0.4393 - val_loss: 1.7417 - val_accuracy: 0.4131\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6887 - accuracy: 0.4418 - val_loss: 1.7434 - val_accuracy: 0.4131\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6890 - accuracy: 0.4408 - val_loss: 1.7453 - val_accuracy: 0.4104\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6884 - accuracy: 0.4423 - val_loss: 1.7402 - val_accuracy: 0.4105\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6884 - accuracy: 0.4415 - val_loss: 1.7426 - val_accuracy: 0.4128\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6878 - accuracy: 0.4415 - val_loss: 1.7401 - val_accuracy: 0.4160\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6884 - accuracy: 0.4409 - val_loss: 1.7418 - val_accuracy: 0.4126\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6885 - accuracy: 0.4420 - val_loss: 1.7442 - val_accuracy: 0.4113\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6880 - accuracy: 0.4413 - val_loss: 1.7450 - val_accuracy: 0.4117\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6876 - accuracy: 0.4404 - val_loss: 1.7408 - val_accuracy: 0.4127\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6875 - accuracy: 0.4411 - val_loss: 1.7397 - val_accuracy: 0.4134\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6878 - accuracy: 0.4411 - val_loss: 1.7403 - val_accuracy: 0.4152\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6874 - accuracy: 0.4418 - val_loss: 1.7391 - val_accuracy: 0.4156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6873 - accuracy: 0.4416 - val_loss: 1.7408 - val_accuracy: 0.4136\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6873 - accuracy: 0.4411 - val_loss: 1.7429 - val_accuracy: 0.4140\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6870 - accuracy: 0.4411 - val_loss: 1.7482 - val_accuracy: 0.4117\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6871 - accuracy: 0.4420 - val_loss: 1.7429 - val_accuracy: 0.4133\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6867 - accuracy: 0.4408 - val_loss: 1.7440 - val_accuracy: 0.4133\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6874 - accuracy: 0.4398 - val_loss: 1.7418 - val_accuracy: 0.4159\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6865 - accuracy: 0.4421 - val_loss: 1.7428 - val_accuracy: 0.4139\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6864 - accuracy: 0.4423 - val_loss: 1.7487 - val_accuracy: 0.4138\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6873 - accuracy: 0.4424 - val_loss: 1.7457 - val_accuracy: 0.4116\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6874 - accuracy: 0.4414 - val_loss: 1.7440 - val_accuracy: 0.4132\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6867 - accuracy: 0.4423 - val_loss: 1.7409 - val_accuracy: 0.4144\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6869 - accuracy: 0.4418 - val_loss: 1.7480 - val_accuracy: 0.4095\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6865 - accuracy: 0.4416 - val_loss: 1.7434 - val_accuracy: 0.4149\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6866 - accuracy: 0.4427 - val_loss: 1.7493 - val_accuracy: 0.4076\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6866 - accuracy: 0.4426 - val_loss: 1.7407 - val_accuracy: 0.4138\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6864 - accuracy: 0.4428 - val_loss: 1.7467 - val_accuracy: 0.4132\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6866 - accuracy: 0.4428 - val_loss: 1.7461 - val_accuracy: 0.4108\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6868 - accuracy: 0.4423 - val_loss: 1.7418 - val_accuracy: 0.4141\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6861 - accuracy: 0.4449 - val_loss: 1.7423 - val_accuracy: 0.4158\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6867 - accuracy: 0.4437 - val_loss: 1.7451 - val_accuracy: 0.4113\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6858 - accuracy: 0.4435 - val_loss: 1.7440 - val_accuracy: 0.4154\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6863 - accuracy: 0.4428 - val_loss: 1.7432 - val_accuracy: 0.4165\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6861 - accuracy: 0.4432 - val_loss: 1.7473 - val_accuracy: 0.4117\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6862 - accuracy: 0.4422 - val_loss: 1.7447 - val_accuracy: 0.4128\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6870 - accuracy: 0.4417 - val_loss: 1.7461 - val_accuracy: 0.4113\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6864 - accuracy: 0.4423 - val_loss: 1.7435 - val_accuracy: 0.4125\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6864 - accuracy: 0.4440 - val_loss: 1.7443 - val_accuracy: 0.4146\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6864 - accuracy: 0.4434 - val_loss: 1.7469 - val_accuracy: 0.4116\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6868 - accuracy: 0.4420 - val_loss: 1.7473 - val_accuracy: 0.4108\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6863 - accuracy: 0.4419 - val_loss: 1.7426 - val_accuracy: 0.4143\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6857 - accuracy: 0.4440 - val_loss: 1.7466 - val_accuracy: 0.4119\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6858 - accuracy: 0.4416 - val_loss: 1.7444 - val_accuracy: 0.4154\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6865 - accuracy: 0.4436 - val_loss: 1.7474 - val_accuracy: 0.4107\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6861 - accuracy: 0.4444 - val_loss: 1.7432 - val_accuracy: 0.4145\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6861 - accuracy: 0.4432 - val_loss: 1.7443 - val_accuracy: 0.4139\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6864 - accuracy: 0.4432 - val_loss: 1.7425 - val_accuracy: 0.4168\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6853 - accuracy: 0.4430 - val_loss: 1.7447 - val_accuracy: 0.4144\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6857 - accuracy: 0.4430 - val_loss: 1.7459 - val_accuracy: 0.4098\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6858 - accuracy: 0.4449 - val_loss: 1.7451 - val_accuracy: 0.4148\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6857 - accuracy: 0.4440 - val_loss: 1.7477 - val_accuracy: 0.4124\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6862 - accuracy: 0.4433 - val_loss: 1.7457 - val_accuracy: 0.4153\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.6855 - accuracy: 0.4443 - val_loss: 1.7482 - val_accuracy: 0.4130\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6861 - accuracy: 0.4431 - val_loss: 1.7443 - val_accuracy: 0.4113\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 1.6860 - accuracy: 0.4441 - val_loss: 1.7462 - val_accuracy: 0.4125\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6858 - accuracy: 0.4437 - val_loss: 1.7445 - val_accuracy: 0.4134\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6859 - accuracy: 0.4417 - val_loss: 1.7470 - val_accuracy: 0.4138\n"
     ]
    }
   ],
   "source": [
    "softmax_regression2 = models.Sequential([\n",
    "    layers.Flatten(input_shape=image_shape),\n",
    "    layers.Dense(10, activation='softmax')],\n",
    "    name='linear')\n",
    "train_model(softmax_regression2, optimizer=optimizers.Adam, n_epochs=100,\n",
    "            learning_rate=2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned weights $W$ can be interpreted as templates. Why is this so? Do they look as you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"500\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W, b = softmax_regression.layers[1].get_weights()\n",
    "templates = W.reshape(32,32,3,10).transpose(3,0,1,2)\n",
    "mini = np.min(templates, axis=(1,2,3), keepdims=True)\n",
    "maxi = np.max(templates, axis=(1,2,3), keepdims=True)\n",
    "rescaled_templates = (templates - mini)/ (maxi-mini)\n",
    "plot_multiple(rescaled_templates, labels, max_columns=5,\n",
    "              imwidth=1, imheight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron\n",
    "\n",
    "Softmax regression has a big limitation: the decision surface between any two classes (i.e. the part of the input space where the classification decision changes from one class to another) is a simple hyperplane (\"flat\").\n",
    "\n",
    "The **multi-layer perceptron** (MLP) is a neural network model with additional layer(s) between the input and the logits (so-called hidden layers), with nonlinear activation functions. Why are activation functions needed?\n",
    "\n",
    "Before recent years, the **hyperbolic tangent** (tanh) function used to be the preferred activation function in hidden layers of MLPs. It is sigmoid shaped and has a range of $(-1,1)$. We can create this in Keras as follows. Does it obtain better results than the linear model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.8144 - accuracy: 0.3726 - val_loss: 1.7377 - val_accuracy: 0.3960\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6811 - accuracy: 0.4244 - val_loss: 1.6751 - val_accuracy: 0.4244\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.6170 - accuracy: 0.4467 - val_loss: 1.6528 - val_accuracy: 0.4309\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.5625 - accuracy: 0.4669 - val_loss: 1.6088 - val_accuracy: 0.4518\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.5155 - accuracy: 0.4864 - val_loss: 1.5783 - val_accuracy: 0.4588\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.4742 - accuracy: 0.5009 - val_loss: 1.5647 - val_accuracy: 0.4620\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.4360 - accuracy: 0.5159 - val_loss: 1.5455 - val_accuracy: 0.4732\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.3957 - accuracy: 0.5274 - val_loss: 1.5339 - val_accuracy: 0.4753\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.3602 - accuracy: 0.5424 - val_loss: 1.5211 - val_accuracy: 0.4769\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.3241 - accuracy: 0.5548 - val_loss: 1.5112 - val_accuracy: 0.4811\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2884 - accuracy: 0.5702 - val_loss: 1.5053 - val_accuracy: 0.4867\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2531 - accuracy: 0.5813 - val_loss: 1.4875 - val_accuracy: 0.4945\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2168 - accuracy: 0.5964 - val_loss: 1.4850 - val_accuracy: 0.4925\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1827 - accuracy: 0.6086 - val_loss: 1.4807 - val_accuracy: 0.4967\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1520 - accuracy: 0.6214 - val_loss: 1.4760 - val_accuracy: 0.4954\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.1194 - accuracy: 0.6324 - val_loss: 1.4839 - val_accuracy: 0.4951\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.0853 - accuracy: 0.6476 - val_loss: 1.4638 - val_accuracy: 0.5011\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.0554 - accuracy: 0.6588 - val_loss: 1.4684 - val_accuracy: 0.5014\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 1.0247 - accuracy: 0.6706 - val_loss: 1.4753 - val_accuracy: 0.4927\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.9928 - accuracy: 0.6826 - val_loss: 1.4729 - val_accuracy: 0.4985\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.9624 - accuracy: 0.6949 - val_loss: 1.4790 - val_accuracy: 0.4967\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.9308 - accuracy: 0.7072 - val_loss: 1.4745 - val_accuracy: 0.5026\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.9036 - accuracy: 0.7181 - val_loss: 1.4780 - val_accuracy: 0.5038\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.8741 - accuracy: 0.7296 - val_loss: 1.4903 - val_accuracy: 0.4961\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.8446 - accuracy: 0.7413 - val_loss: 1.4802 - val_accuracy: 0.5072\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.8195 - accuracy: 0.7505 - val_loss: 1.4931 - val_accuracy: 0.4986\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.7909 - accuracy: 0.7638 - val_loss: 1.4850 - val_accuracy: 0.5029\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.7659 - accuracy: 0.7723 - val_loss: 1.4957 - val_accuracy: 0.5014\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.7393 - accuracy: 0.7803 - val_loss: 1.4986 - val_accuracy: 0.5062\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.7126 - accuracy: 0.7918 - val_loss: 1.5140 - val_accuracy: 0.5013\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.6895 - accuracy: 0.8007 - val_loss: 1.5279 - val_accuracy: 0.4972\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.6664 - accuracy: 0.8099 - val_loss: 1.5341 - val_accuracy: 0.4991\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.6403 - accuracy: 0.8212 - val_loss: 1.5375 - val_accuracy: 0.4965\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.6177 - accuracy: 0.8285 - val_loss: 1.5311 - val_accuracy: 0.4998\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.5943 - accuracy: 0.8386 - val_loss: 1.5576 - val_accuracy: 0.4985\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.5721 - accuracy: 0.8457 - val_loss: 1.5694 - val_accuracy: 0.4957\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.5520 - accuracy: 0.8535 - val_loss: 1.5776 - val_accuracy: 0.4991\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.5300 - accuracy: 0.8621 - val_loss: 1.5803 - val_accuracy: 0.4972\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 0.5109 - accuracy: 0.8691 - val_loss: 1.6034 - val_accuracy: 0.4927\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.4898 - accuracy: 0.8779 - val_loss: 1.6042 - val_accuracy: 0.4937\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.4711 - accuracy: 0.8850 - val_loss: 1.6128 - val_accuracy: 0.4975\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.4535 - accuracy: 0.8904 - val_loss: 1.6215 - val_accuracy: 0.4962\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.4338 - accuracy: 0.8989 - val_loss: 1.6513 - val_accuracy: 0.4902\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.4172 - accuracy: 0.9037 - val_loss: 1.6545 - val_accuracy: 0.4885\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.4007 - accuracy: 0.9090 - val_loss: 1.6644 - val_accuracy: 0.4895\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 0.3825 - accuracy: 0.9145 - val_loss: 1.6777 - val_accuracy: 0.4964\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 0.3670 - accuracy: 0.9208 - val_loss: 1.7021 - val_accuracy: 0.4887\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 0.3509 - accuracy: 0.9258 - val_loss: 1.7084 - val_accuracy: 0.4906\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.3381 - accuracy: 0.9287 - val_loss: 1.7237 - val_accuracy: 0.4887\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.3220 - accuracy: 0.9352 - val_loss: 1.7446 - val_accuracy: 0.4866\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 0.3070 - accuracy: 0.9408 - val_loss: 1.7679 - val_accuracy: 0.4801\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.2931 - accuracy: 0.9440 - val_loss: 1.7649 - val_accuracy: 0.4896\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.2799 - accuracy: 0.9479 - val_loss: 1.7786 - val_accuracy: 0.4943\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2s 32us/sample - loss: 0.2674 - accuracy: 0.9519 - val_loss: 1.8026 - val_accuracy: 0.4846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.2548 - accuracy: 0.9563 - val_loss: 1.8128 - val_accuracy: 0.4881\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.2471 - accuracy: 0.9567 - val_loss: 1.8182 - val_accuracy: 0.4885\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.2323 - accuracy: 0.9621 - val_loss: 1.8365 - val_accuracy: 0.4878\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.2213 - accuracy: 0.9644 - val_loss: 1.8618 - val_accuracy: 0.4901\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.2111 - accuracy: 0.9675 - val_loss: 1.8676 - val_accuracy: 0.4858\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.2020 - accuracy: 0.9699 - val_loss: 1.8931 - val_accuracy: 0.4856\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.1929 - accuracy: 0.9714 - val_loss: 1.9113 - val_accuracy: 0.4822\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.1815 - accuracy: 0.9748 - val_loss: 1.9185 - val_accuracy: 0.4846\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.1721 - accuracy: 0.9770 - val_loss: 1.9499 - val_accuracy: 0.4833\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.1644 - accuracy: 0.9785 - val_loss: 1.9509 - val_accuracy: 0.4842\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.1566 - accuracy: 0.9802 - val_loss: 1.9744 - val_accuracy: 0.4850\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.1500 - accuracy: 0.9813 - val_loss: 2.0103 - val_accuracy: 0.4802\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.1413 - accuracy: 0.9837 - val_loss: 2.0175 - val_accuracy: 0.4865\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.1349 - accuracy: 0.9846 - val_loss: 2.0345 - val_accuracy: 0.4808\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.1257 - accuracy: 0.9869 - val_loss: 2.0537 - val_accuracy: 0.4826\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.1199 - accuracy: 0.9878 - val_loss: 2.0888 - val_accuracy: 0.4835\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.1136 - accuracy: 0.9892 - val_loss: 2.0744 - val_accuracy: 0.4804\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 0.1089 - accuracy: 0.9897 - val_loss: 2.1001 - val_accuracy: 0.4828\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 0.1018 - accuracy: 0.9910 - val_loss: 2.1233 - val_accuracy: 0.4866\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0982 - accuracy: 0.9912 - val_loss: 2.1296 - val_accuracy: 0.4820\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.0915 - accuracy: 0.9922 - val_loss: 2.1591 - val_accuracy: 0.4793\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0877 - accuracy: 0.9931 - val_loss: 2.1902 - val_accuracy: 0.4837\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0813 - accuracy: 0.9938 - val_loss: 2.1897 - val_accuracy: 0.4817\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0782 - accuracy: 0.9938 - val_loss: 2.2284 - val_accuracy: 0.4767\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0756 - accuracy: 0.9942 - val_loss: 2.2436 - val_accuracy: 0.4788\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0706 - accuracy: 0.9951 - val_loss: 2.2633 - val_accuracy: 0.4764\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0657 - accuracy: 0.9956 - val_loss: 2.2714 - val_accuracy: 0.4799\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.0626 - accuracy: 0.9961 - val_loss: 2.2791 - val_accuracy: 0.4792\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.0589 - accuracy: 0.9969 - val_loss: 2.3114 - val_accuracy: 0.4769\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0554 - accuracy: 0.9973 - val_loss: 2.3269 - val_accuracy: 0.4792\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0531 - accuracy: 0.9973 - val_loss: 2.3362 - val_accuracy: 0.4810\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.0495 - accuracy: 0.9975 - val_loss: 2.3773 - val_accuracy: 0.4738\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0481 - accuracy: 0.9978 - val_loss: 2.3799 - val_accuracy: 0.4754\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0465 - accuracy: 0.9973 - val_loss: 2.4222 - val_accuracy: 0.4781\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0446 - accuracy: 0.9978 - val_loss: 2.4268 - val_accuracy: 0.4740\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.0421 - accuracy: 0.9978 - val_loss: 2.4281 - val_accuracy: 0.4800\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0391 - accuracy: 0.9981 - val_loss: 2.4505 - val_accuracy: 0.4763\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.0341 - accuracy: 0.9988 - val_loss: 2.4671 - val_accuracy: 0.4775\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.0325 - accuracy: 0.9988 - val_loss: 2.4846 - val_accuracy: 0.4783\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 0.0331 - accuracy: 0.9985 - val_loss: 2.5221 - val_accuracy: 0.4747\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s 33us/sample - loss: 0.0334 - accuracy: 0.9985 - val_loss: 2.5351 - val_accuracy: 0.4752\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.0313 - accuracy: 0.9982 - val_loss: 2.5432 - val_accuracy: 0.4746\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0271 - accuracy: 0.9991 - val_loss: 2.5804 - val_accuracy: 0.4747\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.0343 - accuracy: 0.9973 - val_loss: 2.5959 - val_accuracy: 0.4748\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.0223 - accuracy: 0.9996 - val_loss: 2.5951 - val_accuracy: 0.4822\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 0.0297 - accuracy: 0.9977 - val_loss: 2.6084 - val_accuracy: 0.4744\n"
     ]
    }
   ],
   "source": [
    "tanh_mlp = models.Sequential([\n",
    "    layers.Flatten(input_shape=image_shape),\n",
    "    layers.Dense(512, activation='tanh'),\n",
    "    layers.Dense(10, activation='softmax')],\n",
    "    name='tanh_mlp')\n",
    "\n",
    "train_model(tanh_mlp, optimizer=optimizers.Adam, learning_rate=2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU\n",
    "\n",
    "The ReLU activation function has become more popular in recent years, especially for deeper nets. Create and train an MLP that uses ReLU as the activation. Do the results change? What benefits does ReLU have against tanh?\n",
    "\n",
    "Good random initialization of weights is important (espeacially for deeper networks). For layers followed by ReLU activation, He et al. (https://arxiv.org/abs/1502.01852) recommend initializing the weights by sampling from a distribution with variance $2/fan_{in}$, where fan in refers to the number of inputs to each unit in the layer. This can be used in Keras simply by setting `kernel_initializer='he_normal'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e96f4ec268fbbe6c",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 2s 41us/sample - loss: 2.5593 - accuracy: 0.4220 - val_loss: 2.2894 - val_accuracy: 0.4717\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 2.1301 - accuracy: 0.4893 - val_loss: 2.0250 - val_accuracy: 0.4878\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.8897 - accuracy: 0.5171 - val_loss: 1.8520 - val_accuracy: 0.5014\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.7340 - accuracy: 0.5371 - val_loss: 1.7456 - val_accuracy: 0.5155\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.6238 - accuracy: 0.5493 - val_loss: 1.6700 - val_accuracy: 0.5159\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.5526 - accuracy: 0.5587 - val_loss: 1.6151 - val_accuracy: 0.5201\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.4938 - accuracy: 0.5727 - val_loss: 1.5922 - val_accuracy: 0.5197\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.4558 - accuracy: 0.5787 - val_loss: 1.5637 - val_accuracy: 0.5270\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.4265 - accuracy: 0.5887 - val_loss: 1.5492 - val_accuracy: 0.5367\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.4013 - accuracy: 0.5953 - val_loss: 1.5375 - val_accuracy: 0.5351\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.3829 - accuracy: 0.6025 - val_loss: 1.5163 - val_accuracy: 0.5393\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.3691 - accuracy: 0.6079 - val_loss: 1.5239 - val_accuracy: 0.5341\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 38us/sample - loss: 1.3555 - accuracy: 0.6107 - val_loss: 1.5222 - val_accuracy: 0.5357\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 2s 39us/sample - loss: 1.3460 - accuracy: 0.6174 - val_loss: 1.5438 - val_accuracy: 0.5357\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 2s 38us/sample - loss: 1.3396 - accuracy: 0.6155 - val_loss: 1.5231 - val_accuracy: 0.5361\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.3262 - accuracy: 0.6245 - val_loss: 1.5178 - val_accuracy: 0.5426\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.3194 - accuracy: 0.6288 - val_loss: 1.5205 - val_accuracy: 0.5444\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.3111 - accuracy: 0.6328 - val_loss: 1.5177 - val_accuracy: 0.5457\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.3094 - accuracy: 0.6343 - val_loss: 1.5295 - val_accuracy: 0.5415\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.3028 - accuracy: 0.6385 - val_loss: 1.5219 - val_accuracy: 0.5410\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2994 - accuracy: 0.6397 - val_loss: 1.5347 - val_accuracy: 0.5419\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.2921 - accuracy: 0.6461 - val_loss: 1.5244 - val_accuracy: 0.5479\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2870 - accuracy: 0.6470 - val_loss: 1.5197 - val_accuracy: 0.5530\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2798 - accuracy: 0.6529 - val_loss: 1.5379 - val_accuracy: 0.5477\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2791 - accuracy: 0.6562 - val_loss: 1.5123 - val_accuracy: 0.5555\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2747 - accuracy: 0.6570 - val_loss: 1.5424 - val_accuracy: 0.5464\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.2716 - accuracy: 0.6592 - val_loss: 1.5466 - val_accuracy: 0.5456\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2660 - accuracy: 0.6616 - val_loss: 1.5327 - val_accuracy: 0.5575\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2607 - accuracy: 0.6655 - val_loss: 1.5653 - val_accuracy: 0.5421\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.2598 - accuracy: 0.6668 - val_loss: 1.5400 - val_accuracy: 0.5525\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2551 - accuracy: 0.6704 - val_loss: 1.5554 - val_accuracy: 0.5495\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.2530 - accuracy: 0.6734 - val_loss: 1.5436 - val_accuracy: 0.5537\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2482 - accuracy: 0.6744 - val_loss: 1.5510 - val_accuracy: 0.5535\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2485 - accuracy: 0.6775 - val_loss: 1.5427 - val_accuracy: 0.5546\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2449 - accuracy: 0.6774 - val_loss: 1.5413 - val_accuracy: 0.5619\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2409 - accuracy: 0.6816 - val_loss: 1.5508 - val_accuracy: 0.5562\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2375 - accuracy: 0.6860 - val_loss: 1.5473 - val_accuracy: 0.5535\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2344 - accuracy: 0.6862 - val_loss: 1.5705 - val_accuracy: 0.5496\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.2356 - accuracy: 0.6876 - val_loss: 1.5648 - val_accuracy: 0.5506\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.2316 - accuracy: 0.6908 - val_loss: 1.5626 - val_accuracy: 0.5557\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2300 - accuracy: 0.6919 - val_loss: 1.5562 - val_accuracy: 0.5615\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2272 - accuracy: 0.6934 - val_loss: 1.5710 - val_accuracy: 0.5538\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2264 - accuracy: 0.6956 - val_loss: 1.5545 - val_accuracy: 0.5638\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2231 - accuracy: 0.6977 - val_loss: 1.5772 - val_accuracy: 0.5547\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2231 - accuracy: 0.6984 - val_loss: 1.5767 - val_accuracy: 0.5588\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2190 - accuracy: 0.7008 - val_loss: 1.5742 - val_accuracy: 0.5548\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2188 - accuracy: 0.7030 - val_loss: 1.5621 - val_accuracy: 0.5626\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.2195 - accuracy: 0.7010 - val_loss: 1.5649 - val_accuracy: 0.5624\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2129 - accuracy: 0.7046 - val_loss: 1.5949 - val_accuracy: 0.5482\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2157 - accuracy: 0.7052 - val_loss: 1.5974 - val_accuracy: 0.5495\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2157 - accuracy: 0.7056 - val_loss: 1.5766 - val_accuracy: 0.5581\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2132 - accuracy: 0.7090 - val_loss: 1.5745 - val_accuracy: 0.5545\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2087 - accuracy: 0.7106 - val_loss: 1.5897 - val_accuracy: 0.5603\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2051 - accuracy: 0.7138 - val_loss: 1.5808 - val_accuracy: 0.5566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2061 - accuracy: 0.7142 - val_loss: 1.5859 - val_accuracy: 0.5618\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2056 - accuracy: 0.7153 - val_loss: 1.6001 - val_accuracy: 0.5514\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.2046 - accuracy: 0.7168 - val_loss: 1.5913 - val_accuracy: 0.5570\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2039 - accuracy: 0.7163 - val_loss: 1.6055 - val_accuracy: 0.5548\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 2s 38us/sample - loss: 1.2007 - accuracy: 0.7194 - val_loss: 1.6164 - val_accuracy: 0.5546\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.2017 - accuracy: 0.7198 - val_loss: 1.6059 - val_accuracy: 0.5531\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.2033 - accuracy: 0.7184 - val_loss: 1.6018 - val_accuracy: 0.5614\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1981 - accuracy: 0.7241 - val_loss: 1.5944 - val_accuracy: 0.5638\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.1927 - accuracy: 0.7260 - val_loss: 1.5936 - val_accuracy: 0.5570\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.1934 - accuracy: 0.7254 - val_loss: 1.5952 - val_accuracy: 0.5616\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.1932 - accuracy: 0.7280 - val_loss: 1.6020 - val_accuracy: 0.5642\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1917 - accuracy: 0.7271 - val_loss: 1.5969 - val_accuracy: 0.5628\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.1911 - accuracy: 0.7294 - val_loss: 1.6263 - val_accuracy: 0.5549\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1954 - accuracy: 0.7271 - val_loss: 1.5918 - val_accuracy: 0.5642\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.1910 - accuracy: 0.7285 - val_loss: 1.6180 - val_accuracy: 0.5574\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.1909 - accuracy: 0.7312 - val_loss: 1.6093 - val_accuracy: 0.5585\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1913 - accuracy: 0.7278 - val_loss: 1.6161 - val_accuracy: 0.5625\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1889 - accuracy: 0.7323 - val_loss: 1.6079 - val_accuracy: 0.5620\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1886 - accuracy: 0.7320 - val_loss: 1.6365 - val_accuracy: 0.5523\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1861 - accuracy: 0.7332 - val_loss: 1.6162 - val_accuracy: 0.5570\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1863 - accuracy: 0.7337 - val_loss: 1.6215 - val_accuracy: 0.5567\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1873 - accuracy: 0.7360 - val_loss: 1.6038 - val_accuracy: 0.5661\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1836 - accuracy: 0.7385 - val_loss: 1.6093 - val_accuracy: 0.5659\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1849 - accuracy: 0.7376 - val_loss: 1.6178 - val_accuracy: 0.5609\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1810 - accuracy: 0.7384 - val_loss: 1.6650 - val_accuracy: 0.5425\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1845 - accuracy: 0.7377 - val_loss: 1.6216 - val_accuracy: 0.5603\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1831 - accuracy: 0.7389 - val_loss: 1.6280 - val_accuracy: 0.5590\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1825 - accuracy: 0.7393 - val_loss: 1.6215 - val_accuracy: 0.5622\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1813 - accuracy: 0.7406 - val_loss: 1.6151 - val_accuracy: 0.5620\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1805 - accuracy: 0.7413 - val_loss: 1.6127 - val_accuracy: 0.5620\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1788 - accuracy: 0.7409 - val_loss: 1.6311 - val_accuracy: 0.5561\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1792 - accuracy: 0.7420 - val_loss: 1.6690 - val_accuracy: 0.5426\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1812 - accuracy: 0.7410 - val_loss: 1.6397 - val_accuracy: 0.5584\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1766 - accuracy: 0.7470 - val_loss: 1.6374 - val_accuracy: 0.5549\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1777 - accuracy: 0.7413 - val_loss: 1.6233 - val_accuracy: 0.5629\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1795 - accuracy: 0.7440 - val_loss: 1.6413 - val_accuracy: 0.5572\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1770 - accuracy: 0.7451 - val_loss: 1.6255 - val_accuracy: 0.5653\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1799 - accuracy: 0.7441 - val_loss: 1.6334 - val_accuracy: 0.5650\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1734 - accuracy: 0.7478 - val_loss: 1.6323 - val_accuracy: 0.5614\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1753 - accuracy: 0.7462 - val_loss: 1.6412 - val_accuracy: 0.5541\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1734 - accuracy: 0.7482 - val_loss: 1.6403 - val_accuracy: 0.5583\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1713 - accuracy: 0.7498 - val_loss: 1.6298 - val_accuracy: 0.5634\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 2s 37us/sample - loss: 1.1725 - accuracy: 0.7508 - val_loss: 1.6503 - val_accuracy: 0.5569\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1747 - accuracy: 0.7501 - val_loss: 1.6386 - val_accuracy: 0.5592\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s 35us/sample - loss: 1.1739 - accuracy: 0.7476 - val_loss: 1.6455 - val_accuracy: 0.5615\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.1698 - accuracy: 0.7503 - val_loss: 1.6475 - val_accuracy: 0.5622\n"
     ]
    }
   ],
   "source": [
    "relu_mlp = models.Sequential([\n",
    "    layers.Flatten(input_shape=image_shape),\n",
    "    layers.Dense(512, activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(1e-3)),\n",
    "    layers.Dense(10, activation='softmax')],\n",
    "    name='relu_mlp_l2reg')\n",
    "train_model(relu_mlp, optimizer=optimizers.Adam, learning_rate=2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Convolutional Neural Network\n",
    "\n",
    "The previous models did not explicitly make use of the grid structure of the image pixels. Convolutional neural networks do.\n",
    "\n",
    "Instead of reshaping the input into a long vector, convolutional layers slide small filters across the input, just as with the convolutional filters we saw earlier in the course. In the earlier parts, we looked at convolution on an image with a single channel in case of grayscale images, or channelwise separate convolutions on RGB images. In CNNs, the multiple input channels of a conv layer are not handled independently, but are linearly combined. This means that the weight array has shape `[kernel_height, kernel_width, num_input_channels, num_output_channels]` and we perform a weighted sum along the channel axis. Another difference is the use of a **bias** vector of shape `[num_output_channels]`, each component of which gets added on the corresponding output channel.\n",
    "\n",
    "As you already know, convolution is a linear operator, so it is possible to express any convolutional layer as a fully-connected layer.\n",
    "However, the convolutional layer's weight matrix is sparse (has many zeros) compared to a fully-connected (\"dense\") layer because each output only depends on a small number of inputs, namely, those within a small neigborhood. Further, the weight values are shared between the different pixel locations.\n",
    "\n",
    "This tutorial has some great visualisations and explanations if you would like to know more: https://arxiv.org/abs/1603.07285.\n",
    "\n",
    "**Q:** Assuming a fixed input image size, do you think the reverse of the above also holds? Can any fully-connected layer be expressed as a convolutional layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a43655d6b36f378f",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Technically, what's called a \"convolutional\" layer is usually implemented as a *cross-correlation* computation. Could there be any advantage in using the actual definition of convolution in these layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9f6f8235182c9277",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the following simple CNN model. It may take about 15 minutes on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 1.6386 - accuracy: 0.5095 - val_loss: 1.3652 - val_accuracy: 0.6084\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 1.2897 - accuracy: 0.6326 - val_loss: 1.2313 - val_accuracy: 0.6511\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 1.1653 - accuracy: 0.6761 - val_loss: 1.1641 - val_accuracy: 0.6798\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 1.0950 - accuracy: 0.7023 - val_loss: 1.1380 - val_accuracy: 0.6832\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 3s 53us/sample - loss: 1.0459 - accuracy: 0.7195 - val_loss: 1.1131 - val_accuracy: 0.6939\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 1.0130 - accuracy: 0.7312 - val_loss: 1.1054 - val_accuracy: 0.6979\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.9920 - accuracy: 0.7392 - val_loss: 1.0809 - val_accuracy: 0.7076\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.9658 - accuracy: 0.7496 - val_loss: 1.0615 - val_accuracy: 0.7135\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.9504 - accuracy: 0.7553 - val_loss: 1.0895 - val_accuracy: 0.7004\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.9404 - accuracy: 0.7605 - val_loss: 1.0695 - val_accuracy: 0.7110\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.9281 - accuracy: 0.7667 - val_loss: 1.0560 - val_accuracy: 0.7243\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.9166 - accuracy: 0.7719 - val_loss: 1.0866 - val_accuracy: 0.7137\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.9060 - accuracy: 0.7755 - val_loss: 1.0931 - val_accuracy: 0.7079\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.9013 - accuracy: 0.7797 - val_loss: 1.0686 - val_accuracy: 0.7194\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8887 - accuracy: 0.7829 - val_loss: 1.0623 - val_accuracy: 0.7237\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8886 - accuracy: 0.7860 - val_loss: 1.0628 - val_accuracy: 0.7166\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8773 - accuracy: 0.7894 - val_loss: 1.0729 - val_accuracy: 0.7207\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8749 - accuracy: 0.7925 - val_loss: 1.0653 - val_accuracy: 0.7226\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8721 - accuracy: 0.7945 - val_loss: 1.1078 - val_accuracy: 0.7082\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8659 - accuracy: 0.7960 - val_loss: 1.0445 - val_accuracy: 0.7314\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8613 - accuracy: 0.7992 - val_loss: 1.0493 - val_accuracy: 0.7297\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8551 - accuracy: 0.8023 - val_loss: 1.0621 - val_accuracy: 0.7244\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8532 - accuracy: 0.8039 - val_loss: 1.0389 - val_accuracy: 0.7359\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8521 - accuracy: 0.8045 - val_loss: 1.0479 - val_accuracy: 0.7321\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.8490 - accuracy: 0.8050 - val_loss: 1.0739 - val_accuracy: 0.7276\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8476 - accuracy: 0.8066 - val_loss: 1.0512 - val_accuracy: 0.7356\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.8442 - accuracy: 0.8083 - val_loss: 1.0753 - val_accuracy: 0.7232\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8409 - accuracy: 0.8084 - val_loss: 1.0510 - val_accuracy: 0.7367\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.8359 - accuracy: 0.8101 - val_loss: 1.0706 - val_accuracy: 0.7337\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8369 - accuracy: 0.8115 - val_loss: 1.0803 - val_accuracy: 0.7228\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.8336 - accuracy: 0.8143 - val_loss: 1.0559 - val_accuracy: 0.7367\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.8357 - accuracy: 0.8128 - val_loss: 1.0771 - val_accuracy: 0.7265\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8275 - accuracy: 0.8162 - val_loss: 1.0596 - val_accuracy: 0.7352\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8319 - accuracy: 0.8163 - val_loss: 1.0684 - val_accuracy: 0.7302\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8256 - accuracy: 0.8199 - val_loss: 1.0913 - val_accuracy: 0.7298\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8254 - accuracy: 0.8177 - val_loss: 1.0533 - val_accuracy: 0.7396\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8251 - accuracy: 0.8200 - val_loss: 1.0626 - val_accuracy: 0.7357\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8207 - accuracy: 0.8206 - val_loss: 1.0758 - val_accuracy: 0.7333\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8200 - accuracy: 0.8236 - val_loss: 1.0803 - val_accuracy: 0.7347\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8214 - accuracy: 0.8219 - val_loss: 1.0589 - val_accuracy: 0.7379\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8163 - accuracy: 0.8244 - val_loss: 1.1056 - val_accuracy: 0.7236\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8225 - accuracy: 0.8224 - val_loss: 1.0715 - val_accuracy: 0.7384\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8125 - accuracy: 0.8266 - val_loss: 1.0589 - val_accuracy: 0.7341\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8122 - accuracy: 0.8254 - val_loss: 1.0904 - val_accuracy: 0.7286\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8107 - accuracy: 0.8274 - val_loss: 1.0729 - val_accuracy: 0.7336\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8131 - accuracy: 0.8271 - val_loss: 1.0983 - val_accuracy: 0.7232\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8121 - accuracy: 0.8274 - val_loss: 1.0734 - val_accuracy: 0.7311\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8113 - accuracy: 0.8279 - val_loss: 1.0505 - val_accuracy: 0.7453\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8116 - accuracy: 0.8284 - val_loss: 1.0577 - val_accuracy: 0.7398\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8065 - accuracy: 0.8300 - val_loss: 1.0648 - val_accuracy: 0.7397\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8060 - accuracy: 0.8294 - val_loss: 1.0774 - val_accuracy: 0.7350\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.8073 - accuracy: 0.8309 - val_loss: 1.0657 - val_accuracy: 0.7390\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8074 - accuracy: 0.8311 - val_loss: 1.0659 - val_accuracy: 0.7390\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8065 - accuracy: 0.8316 - val_loss: 1.0541 - val_accuracy: 0.7386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8079 - accuracy: 0.8301 - val_loss: 1.0842 - val_accuracy: 0.7313\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8057 - accuracy: 0.8299 - val_loss: 1.0708 - val_accuracy: 0.7356\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8039 - accuracy: 0.8309 - val_loss: 1.0704 - val_accuracy: 0.7341\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8010 - accuracy: 0.8324 - val_loss: 1.0553 - val_accuracy: 0.7410\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8032 - accuracy: 0.8321 - val_loss: 1.0797 - val_accuracy: 0.7329\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8041 - accuracy: 0.8322 - val_loss: 1.0662 - val_accuracy: 0.7392\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8010 - accuracy: 0.8361 - val_loss: 1.0569 - val_accuracy: 0.7402\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.7980 - accuracy: 0.8339 - val_loss: 1.0739 - val_accuracy: 0.7310\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8044 - accuracy: 0.8326 - val_loss: 1.0705 - val_accuracy: 0.7355\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8013 - accuracy: 0.8347 - val_loss: 1.0891 - val_accuracy: 0.7297\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8026 - accuracy: 0.8342 - val_loss: 1.0877 - val_accuracy: 0.7343\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.7953 - accuracy: 0.8381 - val_loss: 1.0938 - val_accuracy: 0.7282\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7993 - accuracy: 0.8357 - val_loss: 1.1026 - val_accuracy: 0.7300\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.7953 - accuracy: 0.8368 - val_loss: 1.0913 - val_accuracy: 0.7393\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.7980 - accuracy: 0.8365 - val_loss: 1.0652 - val_accuracy: 0.7460\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.7926 - accuracy: 0.8390 - val_loss: 1.0904 - val_accuracy: 0.7301\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.7970 - accuracy: 0.8360 - val_loss: 1.0951 - val_accuracy: 0.7336\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.7944 - accuracy: 0.8365 - val_loss: 1.0707 - val_accuracy: 0.7368\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.7932 - accuracy: 0.8379 - val_loss: 1.0790 - val_accuracy: 0.7354\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7915 - accuracy: 0.8399 - val_loss: 1.0861 - val_accuracy: 0.7359\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.7915 - accuracy: 0.8394 - val_loss: 1.0937 - val_accuracy: 0.7294\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.7967 - accuracy: 0.8368 - val_loss: 1.1275 - val_accuracy: 0.7211\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.7929 - accuracy: 0.8384 - val_loss: 1.0856 - val_accuracy: 0.7387\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.7931 - accuracy: 0.8392 - val_loss: 1.0999 - val_accuracy: 0.7314\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.7940 - accuracy: 0.8388 - val_loss: 1.0689 - val_accuracy: 0.7409\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.7955 - accuracy: 0.8397 - val_loss: 1.0802 - val_accuracy: 0.7398\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.7912 - accuracy: 0.8396 - val_loss: 1.0952 - val_accuracy: 0.7354\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.7900 - accuracy: 0.8412 - val_loss: 1.0786 - val_accuracy: 0.7353\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.7885 - accuracy: 0.8393 - val_loss: 1.0780 - val_accuracy: 0.7360\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.7882 - accuracy: 0.8416 - val_loss: 1.0719 - val_accuracy: 0.7400\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.7893 - accuracy: 0.8389 - val_loss: 1.0976 - val_accuracy: 0.7306\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.7913 - accuracy: 0.8411 - val_loss: 1.0843 - val_accuracy: 0.7384\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.7874 - accuracy: 0.8428 - val_loss: 1.0691 - val_accuracy: 0.7430\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.7894 - accuracy: 0.8401 - val_loss: 1.0727 - val_accuracy: 0.7387\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7862 - accuracy: 0.8418 - val_loss: 1.1078 - val_accuracy: 0.7352\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7885 - accuracy: 0.8416 - val_loss: 1.0829 - val_accuracy: 0.7358\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7867 - accuracy: 0.8422 - val_loss: 1.0902 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7828 - accuracy: 0.8438 - val_loss: 1.0707 - val_accuracy: 0.7436\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.7852 - accuracy: 0.8432 - val_loss: 1.0652 - val_accuracy: 0.7423\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.7868 - accuracy: 0.8422 - val_loss: 1.0816 - val_accuracy: 0.7415\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.7827 - accuracy: 0.8444 - val_loss: 1.0582 - val_accuracy: 0.7475\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 3s 53us/sample - loss: 0.7844 - accuracy: 0.8429 - val_loss: 1.0997 - val_accuracy: 0.7320\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.7866 - accuracy: 0.8429 - val_loss: 1.1025 - val_accuracy: 0.7341\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7816 - accuracy: 0.8447 - val_loss: 1.0845 - val_accuracy: 0.7353\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7855 - accuracy: 0.8438 - val_loss: 1.0824 - val_accuracy: 0.7380\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7867 - accuracy: 0.8427 - val_loss: 1.0911 - val_accuracy: 0.7340\n"
     ]
    }
   ],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', \n",
    "                  kernel_initializer='he_uniform', padding='same', \n",
    "                  input_shape=image_shape, kernel_regularizer=regularizers.l2(1e-3)),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', \n",
    "                  kernel_initializer='he_uniform', padding='same', kernel_regularizer=regularizers.l2(1e-3)),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(1e-3))],\n",
    "    name='cnn')\n",
    "\n",
    "train_model(cnn, optimizer=optimizers.Adam, learning_rate=1e-3, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Does it improve the result? Does it run faster than the MLP? How many parameters does this model have?\n",
    "\n",
    "**Q:** How large is the output space of the first convolutional layer? How does this compare to the size of the hidden layer in the MLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e6010db8bc2020df",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a CNN Forward Pass\n",
    "\n",
    "To confirm your understanding of the main CNN components, implement the forward pass of the convolutional, max pooling and dense layers, plus the relu and softmax activation functions. For simplicity, assume a fixed filter size of 3x3 for the convolution, with stride 1 and use zero padding, such that the spatial size does not change ('same' padding). Implement this in `conv3x3_same`. For max pooling assume a fixed 2x2 pooling size and stride 2 in `maxpool2x2`.\n",
    "\n",
    "We can extract the weights from the trained Keras model, feed them and an input through your implementation of the forward pass and compare the results.\n",
    "\n",
    "You can also generalize these to other filter sizes and strides.\n",
    "(Implementation of the backward pass does not fit within this exercise, but the \"Machine Learning\" course of our chair does include such exercises.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e8926ce2153b13ca",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations, you got correct results!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"400\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def conv3x3_same(x, weights, biases):\n",
    "    \"\"\"Convolutional layer with filter size 3x3 and 'same' padding.\n",
    "    `x` is a NumPy array of shape [height, width, n_features_in]\n",
    "    `weights` has shape [3, 3, n_features_in, n_features_out]\n",
    "    `biases` has shape [n_features_out]\n",
    "    Return the output of the 3x3 conv (without activation)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    x = np.pad(x, [(1, 1), (1, 1), (0, 0)], mode='constant')\n",
    "    result = np.empty((x.shape[0], x.shape[1], weights.shape[3]))\n",
    "    for i in range(1, x.shape[0] - 1):\n",
    "        for j in range(1, x.shape[1] - 1):\n",
    "            roi = x[i-1:i+2, j-1:j+2]\n",
    "            for c_out in range(weights.shape[3]):\n",
    "                result[i, j, c_out] = np.sum(roi * weights[..., c_out])\n",
    "                \n",
    "    result = result[1:-1, 1:-1]\n",
    "    result += biases\n",
    "    ### END SOLUTION\n",
    "    return result\n",
    "\n",
    "def maxpool2x2(x):\n",
    "    \"\"\"Max pooling with pool size 2x2 and stride 2.\n",
    "    `x` is a numpy array of shape [height, width, n_features]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    result = np.empty((x.shape[0]//2, x.shape[1]//2, x.shape[2]))\n",
    "    for i in range(0, result.shape[0]):\n",
    "        for j in range(0, result.shape[1]):\n",
    "            roi = x[i*2:i*2+2, j*2:j*2+2]\n",
    "            result[i, j] = np.max(roi, axis=(0,1))\n",
    "    ### END SOLUTION\n",
    "    return result\n",
    "\n",
    "def dense(x, weights, biases):\n",
    "    ### BEGIN SOLUTION\n",
    "    return x.T @ weights + biases\n",
    "    ### END SOLUTION\n",
    "    \n",
    "def relu(x):\n",
    "    ### BEGIN SOLUTION\n",
    "    return np.maximum(0, x)\n",
    "    ### END SOLUTION\n",
    "\n",
    "def softmax(x):\n",
    "    ### BEGIN SOLUTION\n",
    "    maxi = np.max(x)\n",
    "    exponentiated = np.exp(x - maxi)\n",
    "    return exponentiated / np.sum(exponentiated)\n",
    "    ### END SOLUTION\n",
    "\n",
    "def my_predict_cnn(x, W1, b1, W2, b2, W3, b3):\n",
    "    x = conv3x3_same(x, W1, b1)\n",
    "    x = relu(x)\n",
    "    x = maxpool2x2(x)\n",
    "    x = conv3x3_same(x, W2, b2)\n",
    "    x = relu(x)\n",
    "    x = maxpool2x2(x)\n",
    "    x = x.reshape(-1)\n",
    "    x = dense(x, W3, b3)\n",
    "    x = softmax(x)\n",
    "    return x\n",
    "\n",
    "W1, b1 = cnn.layers[0].get_weights()\n",
    "W2, b2 = cnn.layers[2].get_weights()\n",
    "W3, b3 = cnn.layers[5].get_weights()\n",
    "\n",
    "i_test = 1\n",
    "inp = x_test[i_test]\n",
    "my_prob = my_predict_cnn(inp, W1, b1, W2, b2, W3, b3)\n",
    "keras_prob = cnn.predict(inp[np.newaxis])[0]\n",
    "if np.mean((my_prob-keras_prob)**2) > 1e-10:\n",
    "    print('Something isn\\'t right! Keras gives different'\n",
    "          'results than my_predict_cnn!')\n",
    "else:\n",
    "    print('Congratulations, you got correct results!')\n",
    "    \n",
    "i_maxpred = np.argmax(my_prob)\n",
    "plot_multiple([im_test[i_test]], \n",
    "              [f'Pred: {labels[i_maxpred]}, {my_prob[i_maxpred]:.1%}'],\n",
    "              imheight=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "Batch normalization is a modern technique to improve and speed up the training of deep neural networks (BatchNorm, Ioffe & Szegedy ICML'15, https://arxiv.org/abs/1502.03167). Each feature channel is normalized to have zero mean and unit variance across the spatial and mini-batch axes. To compensate for the lost degrees of freedom, extra scaling and bias parameters are introduced and learned. Mathematically, BatchNorm for a spatial feature map (e.g. the output of conv) can be written as:\n",
    "\n",
    "$$\n",
    "\\mu_d = \\mathbb{E}\\{x_{\\cdot \\cdot d}\\},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_d = \\sqrt{\\operatorname{Var}\\{x_{\\cdot \\cdot d}\\}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "z_{ijd} = \\gamma_d \\cdot \\frac{x_{ijd} - \\mu_d}{\\sigma_d} + \\beta_d,\n",
    "$$\n",
    "\n",
    "with the expectation and variance taken across both the data samples of the batch and the spatial dimensions.\n",
    "\n",
    "The $\\mu_d$ and $\\sigma_d$ values are computed on the actual mini-batch during training, but at test-time they are fixed, so that the prediction of the final system on a given sample does not depend on other samples in the mini-batch. To obtain the fixed values for test-time use, one needs to maintain moving statistics over the activations during training. This can be a bit tricky to implement from scratch, but luckily this is now implemented in all popular frameworks, including TensorFlow and Keras.\n",
    "\n",
    "**Q:** When applying BatchNorm, it is not necessary to use biases in the previous convolutional layer. Can you explain why?\n",
    "\n",
    "**Q:** Furthermore, if the BatchNorm is followed by a linear or conv layer (with perhaps a ReLU in between), it is not necessary to use the $\\gamma_d$ factor in BatchNorm (it can be turned off as `layers.BatchNormalization(scale=False)`). Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0178a85974e9358e",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a modified version of the previous model, where the `Conv2D` layers don't include the activation any more, and instead, insert a `layers.BatchNormalization()` and a `layers.Activation('relu')` layer after each conv. Does the resulting model obtain better results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-83b754b10f9a5f09",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 4s 73us/sample - loss: 1.4165 - accuracy: 0.5131 - val_loss: 2.2776 - val_accuracy: 0.2902\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 3s 62us/sample - loss: 1.0363 - accuracy: 0.6481 - val_loss: 0.9933 - val_accuracy: 0.6650\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.9119 - accuracy: 0.6944 - val_loss: 1.0664 - val_accuracy: 0.6366\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.8392 - accuracy: 0.7200 - val_loss: 0.9486 - val_accuracy: 0.6886\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.7844 - accuracy: 0.7382 - val_loss: 0.8666 - val_accuracy: 0.7139\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.7447 - accuracy: 0.7563 - val_loss: 0.9227 - val_accuracy: 0.7015\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 3s 61us/sample - loss: 0.7029 - accuracy: 0.7722 - val_loss: 0.8573 - val_accuracy: 0.7278\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 3s 62us/sample - loss: 0.6712 - accuracy: 0.7858 - val_loss: 0.9619 - val_accuracy: 0.6948\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.6472 - accuracy: 0.7953 - val_loss: 0.9797 - val_accuracy: 0.6927\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 3s 62us/sample - loss: 0.6214 - accuracy: 0.8068 - val_loss: 0.8636 - val_accuracy: 0.7304\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.6034 - accuracy: 0.8151 - val_loss: 0.8491 - val_accuracy: 0.7364\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.5824 - accuracy: 0.8240 - val_loss: 0.8658 - val_accuracy: 0.7337\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 3s 63us/sample - loss: 0.5644 - accuracy: 0.8308 - val_loss: 0.9858 - val_accuracy: 0.7050\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 3s 62us/sample - loss: 0.5538 - accuracy: 0.8355 - val_loss: 0.8848 - val_accuracy: 0.7328\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.5351 - accuracy: 0.8442 - val_loss: 0.8697 - val_accuracy: 0.7441\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 3s 61us/sample - loss: 0.5192 - accuracy: 0.8504 - val_loss: 0.9113 - val_accuracy: 0.7235\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.5120 - accuracy: 0.8553 - val_loss: 0.8875 - val_accuracy: 0.7332\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 3s 61us/sample - loss: 0.4987 - accuracy: 0.8619 - val_loss: 0.8644 - val_accuracy: 0.7466\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 3s 61us/sample - loss: 0.4912 - accuracy: 0.8655 - val_loss: 0.8640 - val_accuracy: 0.7472\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 3s 62us/sample - loss: 0.4795 - accuracy: 0.8706 - val_loss: 0.9051 - val_accuracy: 0.7397\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.4635 - accuracy: 0.8788 - val_loss: 0.8981 - val_accuracy: 0.7381\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.4620 - accuracy: 0.8796 - val_loss: 0.8850 - val_accuracy: 0.7475\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.4521 - accuracy: 0.8847 - val_loss: 0.9777 - val_accuracy: 0.7297\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 3s 61us/sample - loss: 0.4441 - accuracy: 0.8894 - val_loss: 0.9752 - val_accuracy: 0.7219\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.4366 - accuracy: 0.8919 - val_loss: 0.9596 - val_accuracy: 0.7331\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.4287 - accuracy: 0.8967 - val_loss: 0.9306 - val_accuracy: 0.7387\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.4281 - accuracy: 0.8975 - val_loss: 0.9456 - val_accuracy: 0.7336\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.4172 - accuracy: 0.9011 - val_loss: 0.9460 - val_accuracy: 0.7415\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.4100 - accuracy: 0.9054 - val_loss: 0.9364 - val_accuracy: 0.7419\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.4071 - accuracy: 0.9076 - val_loss: 1.0046 - val_accuracy: 0.7286\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.4042 - accuracy: 0.9076 - val_loss: 0.9396 - val_accuracy: 0.7433\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.3924 - accuracy: 0.9143 - val_loss: 0.9744 - val_accuracy: 0.7338\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.3889 - accuracy: 0.9166 - val_loss: 0.9521 - val_accuracy: 0.7443\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.3961 - accuracy: 0.9114 - val_loss: 1.0067 - val_accuracy: 0.7265\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3816 - accuracy: 0.9204 - val_loss: 0.9438 - val_accuracy: 0.7463\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3837 - accuracy: 0.9179 - val_loss: 0.9606 - val_accuracy: 0.7449\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3789 - accuracy: 0.9212 - val_loss: 0.9538 - val_accuracy: 0.7393\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3728 - accuracy: 0.9240 - val_loss: 0.9599 - val_accuracy: 0.7438\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.3698 - accuracy: 0.9248 - val_loss: 1.0413 - val_accuracy: 0.7189\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3628 - accuracy: 0.9296 - val_loss: 0.9971 - val_accuracy: 0.7251\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 3s 62us/sample - loss: 0.3640 - accuracy: 0.9274 - val_loss: 0.9426 - val_accuracy: 0.7443\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 3s 61us/sample - loss: 0.3568 - accuracy: 0.9306 - val_loss: 1.0583 - val_accuracy: 0.7205\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.3595 - accuracy: 0.9294 - val_loss: 0.9865 - val_accuracy: 0.7365\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.3467 - accuracy: 0.9368 - val_loss: 0.9682 - val_accuracy: 0.7449\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 3s 61us/sample - loss: 0.3500 - accuracy: 0.9351 - val_loss: 0.9345 - val_accuracy: 0.7488\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.3509 - accuracy: 0.9332 - val_loss: 0.9829 - val_accuracy: 0.7366\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.3492 - accuracy: 0.9346 - val_loss: 0.9759 - val_accuracy: 0.7429\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3419 - accuracy: 0.9385 - val_loss: 0.9542 - val_accuracy: 0.7474\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3404 - accuracy: 0.9387 - val_loss: 0.9707 - val_accuracy: 0.7420\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3372 - accuracy: 0.9403 - val_loss: 0.9412 - val_accuracy: 0.7506\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3385 - accuracy: 0.9397 - val_loss: 0.9715 - val_accuracy: 0.7441\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3335 - accuracy: 0.9425 - val_loss: 0.9973 - val_accuracy: 0.7396\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3360 - accuracy: 0.9411 - val_loss: 0.9823 - val_accuracy: 0.7429\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3217 - accuracy: 0.9482 - val_loss: 0.9944 - val_accuracy: 0.7327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3292 - accuracy: 0.9430 - val_loss: 1.0040 - val_accuracy: 0.7351\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3202 - accuracy: 0.9488 - val_loss: 1.0192 - val_accuracy: 0.7376\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3214 - accuracy: 0.9465 - val_loss: 0.9790 - val_accuracy: 0.7415\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3200 - accuracy: 0.9479 - val_loss: 0.9684 - val_accuracy: 0.7432\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3169 - accuracy: 0.9486 - val_loss: 0.9727 - val_accuracy: 0.7470\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3182 - accuracy: 0.9489 - val_loss: 0.9852 - val_accuracy: 0.7398\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3078 - accuracy: 0.9529 - val_loss: 0.9696 - val_accuracy: 0.7466\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3112 - accuracy: 0.9514 - val_loss: 0.9743 - val_accuracy: 0.7465\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3121 - accuracy: 0.9504 - val_loss: 1.0529 - val_accuracy: 0.7292\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.3093 - accuracy: 0.9525 - val_loss: 1.1020 - val_accuracy: 0.7224\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.3077 - accuracy: 0.9530 - val_loss: 0.9593 - val_accuracy: 0.7499\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3036 - accuracy: 0.9552 - val_loss: 0.9834 - val_accuracy: 0.7479\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3006 - accuracy: 0.9568 - val_loss: 0.9954 - val_accuracy: 0.7383\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3044 - accuracy: 0.9539 - val_loss: 1.0153 - val_accuracy: 0.7448\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2982 - accuracy: 0.9570 - val_loss: 0.9951 - val_accuracy: 0.7437\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.3001 - accuracy: 0.9561 - val_loss: 0.9594 - val_accuracy: 0.7504\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2969 - accuracy: 0.9576 - val_loss: 1.0756 - val_accuracy: 0.7275\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.3011 - accuracy: 0.9554 - val_loss: 1.0727 - val_accuracy: 0.7310\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2921 - accuracy: 0.9599 - val_loss: 1.0360 - val_accuracy: 0.7330\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2933 - accuracy: 0.9582 - val_loss: 1.0034 - val_accuracy: 0.7361\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2914 - accuracy: 0.9591 - val_loss: 1.0036 - val_accuracy: 0.7362\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2922 - accuracy: 0.9591 - val_loss: 0.9520 - val_accuracy: 0.7557\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2878 - accuracy: 0.9598 - val_loss: 0.9629 - val_accuracy: 0.7481\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2875 - accuracy: 0.9616 - val_loss: 1.0108 - val_accuracy: 0.7417\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2834 - accuracy: 0.9630 - val_loss: 1.0427 - val_accuracy: 0.7322\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2866 - accuracy: 0.9609 - val_loss: 1.0661 - val_accuracy: 0.7247\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2900 - accuracy: 0.9591 - val_loss: 1.0098 - val_accuracy: 0.7335\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2845 - accuracy: 0.9623 - val_loss: 1.0152 - val_accuracy: 0.7404\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.2843 - accuracy: 0.9610 - val_loss: 1.0640 - val_accuracy: 0.7314\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2753 - accuracy: 0.9668 - val_loss: 0.9882 - val_accuracy: 0.7419\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2828 - accuracy: 0.9612 - val_loss: 1.0684 - val_accuracy: 0.7262\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2831 - accuracy: 0.9614 - val_loss: 1.0184 - val_accuracy: 0.7347\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2737 - accuracy: 0.9666 - val_loss: 1.0260 - val_accuracy: 0.7369\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2813 - accuracy: 0.9631 - val_loss: 1.0115 - val_accuracy: 0.7376\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2760 - accuracy: 0.9656 - val_loss: 0.9920 - val_accuracy: 0.7530\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2787 - accuracy: 0.9634 - val_loss: 0.9884 - val_accuracy: 0.7423\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2774 - accuracy: 0.9644 - val_loss: 0.9538 - val_accuracy: 0.7504\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2705 - accuracy: 0.9688 - val_loss: 0.9434 - val_accuracy: 0.7526\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2731 - accuracy: 0.9663 - val_loss: 0.9769 - val_accuracy: 0.7493\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2733 - accuracy: 0.9652 - val_loss: 1.0372 - val_accuracy: 0.7407\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2745 - accuracy: 0.9656 - val_loss: 1.0252 - val_accuracy: 0.7309\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.2731 - accuracy: 0.9658 - val_loss: 1.0035 - val_accuracy: 0.7378\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2687 - accuracy: 0.9686 - val_loss: 0.9790 - val_accuracy: 0.7438\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.2723 - accuracy: 0.9663 - val_loss: 1.0297 - val_accuracy: 0.7389\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.2633 - accuracy: 0.9698 - val_loss: 1.0271 - val_accuracy: 0.7373\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.2640 - accuracy: 0.9702 - val_loss: 1.0957 - val_accuracy: 0.7339\n"
     ]
    }
   ],
   "source": [
    "cnn_batchnorm = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "cnn_batchnorm = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), use_bias=False,\n",
    "                  padding='same', input_shape=image_shape),\n",
    "    layers.BatchNormalization(scale=False),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D((2, 2), (2,2)),\n",
    "    layers.Conv2D(64, (3, 3), use_bias=False,\n",
    "                  padding='same'),\n",
    "    layers.BatchNormalization(scale=False),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(1e-3))],\n",
    "    name='cnn_batchnorm')\n",
    "### END SOLUTION\n",
    "\n",
    "train_model(cnn_batchnorm, optimizer=optimizers.Adam,\n",
    "            learning_rate=1e-3, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strided Convolutions\n",
    "\n",
    "Max-pooling is a popular technique for reducing the spatial dimensionality\n",
    "of the outputs from conv layers. However, researchers such as Springenberg et al. have argued\n",
    "that simple striding can achieve similar accuracy (https://arxiv.org/pdf/1412.6806.pdf). \n",
    "\n",
    "Now create a model using the same architecture as before, with the difference of\n",
    "removing the pooling layers and increasing the stride parameter of the conv layers to $2 \\times 2$ in the spatial dimensions. \n",
    "\n",
    "What differences do you notice when running the training?\n",
    "What seems to be a clear advantage for using strides and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-34f5d6a1166b46fa",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0624 03:23:35.891220 140494717568832 deprecation.py:323] From /home/sarandi/anaconda3/envs/ml-tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.4634 - accuracy: 0.4901 - val_loss: 2.4058 - val_accuracy: 0.2717\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 1.1055 - accuracy: 0.6195 - val_loss: 1.0847 - val_accuracy: 0.6282\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.9696 - accuracy: 0.6716 - val_loss: 1.0455 - val_accuracy: 0.6449\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8842 - accuracy: 0.7069 - val_loss: 1.0198 - val_accuracy: 0.6605\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.8277 - accuracy: 0.7286 - val_loss: 1.0218 - val_accuracy: 0.6602\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 3s 53us/sample - loss: 0.7867 - accuracy: 0.7454 - val_loss: 0.9738 - val_accuracy: 0.6841\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.7468 - accuracy: 0.7623 - val_loss: 1.0077 - val_accuracy: 0.6764\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7202 - accuracy: 0.7751 - val_loss: 0.9923 - val_accuracy: 0.6832\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6924 - accuracy: 0.7850 - val_loss: 1.0279 - val_accuracy: 0.6781\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.6708 - accuracy: 0.7984 - val_loss: 1.0087 - val_accuracy: 0.6858\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.6501 - accuracy: 0.8078 - val_loss: 1.0074 - val_accuracy: 0.6905\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.6298 - accuracy: 0.8154 - val_loss: 1.0232 - val_accuracy: 0.6886\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6149 - accuracy: 0.8241 - val_loss: 1.0830 - val_accuracy: 0.6740\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 2s 47us/sample - loss: 0.6007 - accuracy: 0.8325 - val_loss: 1.0330 - val_accuracy: 0.6926\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.5843 - accuracy: 0.8405 - val_loss: 1.0660 - val_accuracy: 0.6854\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.5736 - accuracy: 0.8438 - val_loss: 1.0677 - val_accuracy: 0.6924\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5615 - accuracy: 0.8515 - val_loss: 1.1232 - val_accuracy: 0.6737\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.5572 - accuracy: 0.8535 - val_loss: 1.0622 - val_accuracy: 0.6954\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.5416 - accuracy: 0.8608 - val_loss: 1.1268 - val_accuracy: 0.6792\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.5323 - accuracy: 0.8650 - val_loss: 1.1269 - val_accuracy: 0.6862\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5232 - accuracy: 0.8715 - val_loss: 1.1006 - val_accuracy: 0.6888\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5155 - accuracy: 0.8733 - val_loss: 1.1380 - val_accuracy: 0.6816\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.5092 - accuracy: 0.8774 - val_loss: 1.1314 - val_accuracy: 0.6864\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.5072 - accuracy: 0.8782 - val_loss: 1.1636 - val_accuracy: 0.6847\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4966 - accuracy: 0.8847 - val_loss: 1.1145 - val_accuracy: 0.6898\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4892 - accuracy: 0.8879 - val_loss: 1.1802 - val_accuracy: 0.6816\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4827 - accuracy: 0.8906 - val_loss: 1.1677 - val_accuracy: 0.6775\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4761 - accuracy: 0.8945 - val_loss: 1.1247 - val_accuracy: 0.6936\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4753 - accuracy: 0.8946 - val_loss: 1.1926 - val_accuracy: 0.6814\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4653 - accuracy: 0.8994 - val_loss: 1.1696 - val_accuracy: 0.6840\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4614 - accuracy: 0.9022 - val_loss: 1.1913 - val_accuracy: 0.6758\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4558 - accuracy: 0.9025 - val_loss: 1.1868 - val_accuracy: 0.6840\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4538 - accuracy: 0.9050 - val_loss: 1.1561 - val_accuracy: 0.6912\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4447 - accuracy: 0.9095 - val_loss: 1.2264 - val_accuracy: 0.6765\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4431 - accuracy: 0.9103 - val_loss: 1.2246 - val_accuracy: 0.6733\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4383 - accuracy: 0.9115 - val_loss: 1.1791 - val_accuracy: 0.6867\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4344 - accuracy: 0.9140 - val_loss: 1.1888 - val_accuracy: 0.6848\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4323 - accuracy: 0.9153 - val_loss: 1.1931 - val_accuracy: 0.6875\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4299 - accuracy: 0.9145 - val_loss: 1.2145 - val_accuracy: 0.6770\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4264 - accuracy: 0.9172 - val_loss: 1.2324 - val_accuracy: 0.6772\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4252 - accuracy: 0.9195 - val_loss: 1.1886 - val_accuracy: 0.6838\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4203 - accuracy: 0.9196 - val_loss: 1.1701 - val_accuracy: 0.6874\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.4099 - accuracy: 0.9259 - val_loss: 1.2005 - val_accuracy: 0.6826\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4119 - accuracy: 0.9247 - val_loss: 1.2007 - val_accuracy: 0.6875\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4123 - accuracy: 0.9243 - val_loss: 1.2038 - val_accuracy: 0.6925\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4051 - accuracy: 0.9289 - val_loss: 1.2059 - val_accuracy: 0.6825\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4049 - accuracy: 0.9279 - val_loss: 1.2414 - val_accuracy: 0.6769\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4029 - accuracy: 0.9287 - val_loss: 1.2091 - val_accuracy: 0.6853\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.3996 - accuracy: 0.9306 - val_loss: 1.2270 - val_accuracy: 0.6806\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3928 - accuracy: 0.9339 - val_loss: 1.2422 - val_accuracy: 0.6767\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3947 - accuracy: 0.9324 - val_loss: 1.2205 - val_accuracy: 0.6806\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3867 - accuracy: 0.9357 - val_loss: 1.2503 - val_accuracy: 0.6811\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3922 - accuracy: 0.9310 - val_loss: 1.2436 - val_accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 3s 50us/sample - loss: 0.3853 - accuracy: 0.9367 - val_loss: 1.2227 - val_accuracy: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3868 - accuracy: 0.9363 - val_loss: 1.2466 - val_accuracy: 0.6791\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3788 - accuracy: 0.9391 - val_loss: 1.2279 - val_accuracy: 0.6879\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3762 - accuracy: 0.9400 - val_loss: 1.2479 - val_accuracy: 0.6753\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3814 - accuracy: 0.9370 - val_loss: 1.2153 - val_accuracy: 0.6891\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3778 - accuracy: 0.9396 - val_loss: 1.2558 - val_accuracy: 0.6805\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3703 - accuracy: 0.9429 - val_loss: 1.2751 - val_accuracy: 0.6775\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3757 - accuracy: 0.9387 - val_loss: 1.2439 - val_accuracy: 0.6830\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3755 - accuracy: 0.9402 - val_loss: 1.2748 - val_accuracy: 0.6726\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3721 - accuracy: 0.9399 - val_loss: 1.2891 - val_accuracy: 0.6733\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3693 - accuracy: 0.9428 - val_loss: 1.2206 - val_accuracy: 0.6819\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3641 - accuracy: 0.9444 - val_loss: 1.2535 - val_accuracy: 0.6791\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3611 - accuracy: 0.9466 - val_loss: 1.2348 - val_accuracy: 0.6851\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3592 - accuracy: 0.9480 - val_loss: 1.2584 - val_accuracy: 0.6769\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3637 - accuracy: 0.9446 - val_loss: 1.2704 - val_accuracy: 0.6739\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3626 - accuracy: 0.9453 - val_loss: 1.2435 - val_accuracy: 0.6798\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.3562 - accuracy: 0.9482 - val_loss: 1.2890 - val_accuracy: 0.6734\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3554 - accuracy: 0.9488 - val_loss: 1.2696 - val_accuracy: 0.6797\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.3554 - accuracy: 0.9479 - val_loss: 1.2443 - val_accuracy: 0.6827\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3535 - accuracy: 0.9498 - val_loss: 1.2522 - val_accuracy: 0.6786\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3488 - accuracy: 0.9526 - val_loss: 1.2368 - val_accuracy: 0.6863\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3547 - accuracy: 0.9478 - val_loss: 1.2948 - val_accuracy: 0.6699\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3463 - accuracy: 0.9527 - val_loss: 1.2935 - val_accuracy: 0.6716\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3533 - accuracy: 0.9481 - val_loss: 1.2572 - val_accuracy: 0.6831\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3519 - accuracy: 0.9495 - val_loss: 1.2757 - val_accuracy: 0.6778\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3425 - accuracy: 0.9537 - val_loss: 1.2897 - val_accuracy: 0.6768\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3436 - accuracy: 0.9534 - val_loss: 1.2898 - val_accuracy: 0.6682\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.3448 - accuracy: 0.9530 - val_loss: 1.2765 - val_accuracy: 0.6771\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3484 - accuracy: 0.9509 - val_loss: 1.2957 - val_accuracy: 0.6720\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3436 - accuracy: 0.9523 - val_loss: 1.2902 - val_accuracy: 0.6756\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3406 - accuracy: 0.9544 - val_loss: 1.2694 - val_accuracy: 0.6707\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 3s 51us/sample - loss: 0.3387 - accuracy: 0.9546 - val_loss: 1.2993 - val_accuracy: 0.6762\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3385 - accuracy: 0.9554 - val_loss: 1.2782 - val_accuracy: 0.6673\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3340 - accuracy: 0.9579 - val_loss: 1.2622 - val_accuracy: 0.6807\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3413 - accuracy: 0.9527 - val_loss: 1.2765 - val_accuracy: 0.6777\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3340 - accuracy: 0.9577 - val_loss: 1.2707 - val_accuracy: 0.6758\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3369 - accuracy: 0.9554 - val_loss: 1.2798 - val_accuracy: 0.6756\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3322 - accuracy: 0.9574 - val_loss: 1.2913 - val_accuracy: 0.6681\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3342 - accuracy: 0.9571 - val_loss: 1.2918 - val_accuracy: 0.6687\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3339 - accuracy: 0.9557 - val_loss: 1.3112 - val_accuracy: 0.6733\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3312 - accuracy: 0.9577 - val_loss: 1.2958 - val_accuracy: 0.6719\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3315 - accuracy: 0.9576 - val_loss: 1.2939 - val_accuracy: 0.6711\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3288 - accuracy: 0.9591 - val_loss: 1.2494 - val_accuracy: 0.6823\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3266 - accuracy: 0.9604 - val_loss: 1.3137 - val_accuracy: 0.6728\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3306 - accuracy: 0.9573 - val_loss: 1.2882 - val_accuracy: 0.6695\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3254 - accuracy: 0.9611 - val_loss: 1.3101 - val_accuracy: 0.6645\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3263 - accuracy: 0.9601 - val_loss: 1.2962 - val_accuracy: 0.6705\n"
     ]
    }
   ],
   "source": [
    "cnn_strides = ...\n",
    "### BEGIN SOLUTION\n",
    "cnn_strides = models.Sequential([\n",
    "    layers.Conv2D(64, 3, strides=2, use_bias=False, \n",
    "                  padding='same', input_shape=image_shape),\n",
    "    layers.BatchNormalization(scale=False),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(64, 3, strides=2, use_bias=False, padding='same'),\n",
    "    layers.BatchNormalization(scale=False),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(1e-3))],\n",
    "    name='cnn_strides')\n",
    "### END SOLUTION\n",
    "\n",
    "train_model(cnn_strides, optimizer=optimizers.Adam,\n",
    "            learning_rate=1e-3, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Pooling\n",
    "\n",
    "The above network ends in a `Flatten` layer followed by a `Dense` layer, in which the number of weights depends on the input size. This means that testing can only be performed on the exact same image size. Instead of flattening, several architectures employ a (spatial) **global average pooling layer** to produce of vector of fixed size that is independent of image size, describing the whole image. This is simply the spatial average of the feature values over each feature channel.\n",
    "\n",
    "For this to work well, the units before the average pooling need to have a large enough receptive field. Therefore, compared with the previous model, remove the `Flatten` layer and instead add a third Conv-BatchNorm-ReLU combination, followed by a `layers.GlobalAveragePooling2D()` layer (before the final `Dense` layer).\n",
    "\n",
    "**Q:** Which network has more parameters, this or the previous one?\n",
    "\n",
    "**Q:** What is the receptive field of the units in the layer directly before the global average pooling?\n",
    "\n",
    "Train it and see if it reaches similar accuracy to the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-37d949e926b6cfd3",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 4s 70us/sample - loss: 1.5961 - accuracy: 0.4367 - val_loss: 2.6062 - val_accuracy: 0.1641\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.3111 - accuracy: 0.5483 - val_loss: 1.3121 - val_accuracy: 0.5479\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 1.2041 - accuracy: 0.5919 - val_loss: 1.2227 - val_accuracy: 0.5801\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 1.1316 - accuracy: 0.6177 - val_loss: 1.1934 - val_accuracy: 0.5941\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 1.0883 - accuracy: 0.6342 - val_loss: 1.2056 - val_accuracy: 0.5856\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 3s 63us/sample - loss: 1.0484 - accuracy: 0.6495 - val_loss: 1.1018 - val_accuracy: 0.6221\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 3s 61us/sample - loss: 1.0151 - accuracy: 0.6640 - val_loss: 1.0739 - val_accuracy: 0.6368\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.9913 - accuracy: 0.6719 - val_loss: 1.0688 - val_accuracy: 0.6422\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 3s 63us/sample - loss: 0.9640 - accuracy: 0.6838 - val_loss: 1.1255 - val_accuracy: 0.6224\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.9502 - accuracy: 0.6880 - val_loss: 1.0414 - val_accuracy: 0.6575\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 3s 63us/sample - loss: 0.9295 - accuracy: 0.6964 - val_loss: 1.1768 - val_accuracy: 0.6166\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 3s 64us/sample - loss: 0.9185 - accuracy: 0.7019 - val_loss: 1.1081 - val_accuracy: 0.6228\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.9003 - accuracy: 0.7082 - val_loss: 1.0722 - val_accuracy: 0.6423\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.8893 - accuracy: 0.7148 - val_loss: 1.0668 - val_accuracy: 0.6493\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.8795 - accuracy: 0.7157 - val_loss: 1.0070 - val_accuracy: 0.6699\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.8685 - accuracy: 0.7220 - val_loss: 1.0715 - val_accuracy: 0.6433\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.8575 - accuracy: 0.7239 - val_loss: 1.0475 - val_accuracy: 0.6620\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.8479 - accuracy: 0.7294 - val_loss: 1.0536 - val_accuracy: 0.6496\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.8392 - accuracy: 0.7328 - val_loss: 1.0617 - val_accuracy: 0.6507\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.8317 - accuracy: 0.7364 - val_loss: 1.0229 - val_accuracy: 0.6631\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.8185 - accuracy: 0.7434 - val_loss: 1.0283 - val_accuracy: 0.6653\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.8136 - accuracy: 0.7432 - val_loss: 1.1469 - val_accuracy: 0.6263\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.8092 - accuracy: 0.7438 - val_loss: 0.9783 - val_accuracy: 0.6802\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.7998 - accuracy: 0.7494 - val_loss: 1.0278 - val_accuracy: 0.6611\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.7930 - accuracy: 0.7508 - val_loss: 1.1039 - val_accuracy: 0.6395\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.7833 - accuracy: 0.7554 - val_loss: 1.0580 - val_accuracy: 0.6560\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.7802 - accuracy: 0.7578 - val_loss: 1.0308 - val_accuracy: 0.6648\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.7759 - accuracy: 0.7569 - val_loss: 1.0782 - val_accuracy: 0.6456\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.7668 - accuracy: 0.7626 - val_loss: 1.0669 - val_accuracy: 0.6516\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.7630 - accuracy: 0.7624 - val_loss: 1.0509 - val_accuracy: 0.6587\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.7582 - accuracy: 0.7630 - val_loss: 1.0848 - val_accuracy: 0.6504\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.7504 - accuracy: 0.7680 - val_loss: 1.2185 - val_accuracy: 0.6100\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.7437 - accuracy: 0.7692 - val_loss: 0.9805 - val_accuracy: 0.6831\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.7421 - accuracy: 0.7709 - val_loss: 1.0508 - val_accuracy: 0.6637\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.7324 - accuracy: 0.7760 - val_loss: 1.1394 - val_accuracy: 0.6345\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.7286 - accuracy: 0.7759 - val_loss: 1.0287 - val_accuracy: 0.6735\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.7249 - accuracy: 0.7781 - val_loss: 1.0405 - val_accuracy: 0.6632\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.7201 - accuracy: 0.7800 - val_loss: 1.0281 - val_accuracy: 0.6694\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.7157 - accuracy: 0.7812 - val_loss: 1.0006 - val_accuracy: 0.6798\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.7108 - accuracy: 0.7830 - val_loss: 1.0390 - val_accuracy: 0.6651\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.7081 - accuracy: 0.7839 - val_loss: 1.0653 - val_accuracy: 0.6588\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.7047 - accuracy: 0.7855 - val_loss: 1.0138 - val_accuracy: 0.6744\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.7007 - accuracy: 0.7868 - val_loss: 1.0233 - val_accuracy: 0.6789\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.6933 - accuracy: 0.7890 - val_loss: 1.0220 - val_accuracy: 0.6781\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.6924 - accuracy: 0.7920 - val_loss: 1.0721 - val_accuracy: 0.6607\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.6878 - accuracy: 0.7915 - val_loss: 1.0376 - val_accuracy: 0.6683\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.6829 - accuracy: 0.7945 - val_loss: 1.0528 - val_accuracy: 0.6611\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.6786 - accuracy: 0.7968 - val_loss: 1.0485 - val_accuracy: 0.6709\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.6767 - accuracy: 0.7940 - val_loss: 0.9748 - val_accuracy: 0.6928\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.6719 - accuracy: 0.7980 - val_loss: 1.0518 - val_accuracy: 0.6650\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.6695 - accuracy: 0.7990 - val_loss: 1.0015 - val_accuracy: 0.6855\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.6673 - accuracy: 0.7992 - val_loss: 1.1616 - val_accuracy: 0.6293\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.6624 - accuracy: 0.8022 - val_loss: 1.1734 - val_accuracy: 0.6333\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.6595 - accuracy: 0.8024 - val_loss: 1.0274 - val_accuracy: 0.6732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.6557 - accuracy: 0.8048 - val_loss: 1.1422 - val_accuracy: 0.6477\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.6547 - accuracy: 0.8045 - val_loss: 1.0314 - val_accuracy: 0.6777\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.6490 - accuracy: 0.8066 - val_loss: 1.1457 - val_accuracy: 0.6440\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.6476 - accuracy: 0.8054 - val_loss: 1.0990 - val_accuracy: 0.6570\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.6449 - accuracy: 0.8086 - val_loss: 1.0171 - val_accuracy: 0.6793\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.6393 - accuracy: 0.8092 - val_loss: 1.0774 - val_accuracy: 0.6675\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.6380 - accuracy: 0.8117 - val_loss: 1.0743 - val_accuracy: 0.6626\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.6360 - accuracy: 0.8109 - val_loss: 1.0334 - val_accuracy: 0.6769\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.6339 - accuracy: 0.8109 - val_loss: 1.0445 - val_accuracy: 0.6756\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.6292 - accuracy: 0.8148 - val_loss: 1.0310 - val_accuracy: 0.6719\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.6283 - accuracy: 0.8146 - val_loss: 1.0070 - val_accuracy: 0.6875\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.6209 - accuracy: 0.8174 - val_loss: 1.0017 - val_accuracy: 0.6858\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 3s 62us/sample - loss: 0.6207 - accuracy: 0.8154 - val_loss: 1.2210 - val_accuracy: 0.6388\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.6164 - accuracy: 0.8189 - val_loss: 1.1154 - val_accuracy: 0.6560\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.6152 - accuracy: 0.8198 - val_loss: 1.0829 - val_accuracy: 0.6618\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.6147 - accuracy: 0.8196 - val_loss: 1.0905 - val_accuracy: 0.6698\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.6119 - accuracy: 0.8194 - val_loss: 1.0213 - val_accuracy: 0.6815\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.6063 - accuracy: 0.8240 - val_loss: 1.1052 - val_accuracy: 0.6580\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.6080 - accuracy: 0.8224 - val_loss: 1.1200 - val_accuracy: 0.6572\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 3s 58us/sample - loss: 0.5989 - accuracy: 0.8254 - val_loss: 1.0875 - val_accuracy: 0.6640\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 3s 60us/sample - loss: 0.6002 - accuracy: 0.8246 - val_loss: 1.0545 - val_accuracy: 0.6682\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.5961 - accuracy: 0.8268 - val_loss: 0.9874 - val_accuracy: 0.6955\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.5950 - accuracy: 0.8254 - val_loss: 1.0953 - val_accuracy: 0.6625\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5973 - accuracy: 0.8250 - val_loss: 1.0789 - val_accuracy: 0.6719\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5973 - accuracy: 0.8252 - val_loss: 1.1239 - val_accuracy: 0.6579\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5893 - accuracy: 0.8292 - val_loss: 1.0928 - val_accuracy: 0.6658\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5868 - accuracy: 0.8310 - val_loss: 1.0789 - val_accuracy: 0.6639\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.5856 - accuracy: 0.8312 - val_loss: 1.0517 - val_accuracy: 0.6700\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.5832 - accuracy: 0.8314 - val_loss: 1.0781 - val_accuracy: 0.6701\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5780 - accuracy: 0.8350 - val_loss: 1.0941 - val_accuracy: 0.6642\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 0.5785 - accuracy: 0.8346 - val_loss: 1.0386 - val_accuracy: 0.6819\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5777 - accuracy: 0.8340 - val_loss: 1.1902 - val_accuracy: 0.6467\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.5758 - accuracy: 0.8344 - val_loss: 1.0767 - val_accuracy: 0.6722\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5717 - accuracy: 0.8351 - val_loss: 1.0955 - val_accuracy: 0.6725\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.5711 - accuracy: 0.8361 - val_loss: 1.1018 - val_accuracy: 0.6674\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5687 - accuracy: 0.8377 - val_loss: 1.1452 - val_accuracy: 0.6509\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5699 - accuracy: 0.8371 - val_loss: 1.0486 - val_accuracy: 0.6783\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.5652 - accuracy: 0.8384 - val_loss: 1.0753 - val_accuracy: 0.6774\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5615 - accuracy: 0.8400 - val_loss: 1.1197 - val_accuracy: 0.6552\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.5639 - accuracy: 0.8383 - val_loss: 1.0880 - val_accuracy: 0.6718\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5618 - accuracy: 0.8395 - val_loss: 1.1557 - val_accuracy: 0.6619\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.5630 - accuracy: 0.8394 - val_loss: 1.0376 - val_accuracy: 0.6812\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.5593 - accuracy: 0.8388 - val_loss: 1.0988 - val_accuracy: 0.6657\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.5567 - accuracy: 0.8435 - val_loss: 1.1304 - val_accuracy: 0.6560\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5506 - accuracy: 0.8455 - val_loss: 1.1129 - val_accuracy: 0.6692\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.5496 - accuracy: 0.8441 - val_loss: 1.0710 - val_accuracy: 0.6694\n"
     ]
    }
   ],
   "source": [
    "cnn_global_pool = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "cnn_global_pool = models.Sequential([\n",
    "    layers.Conv2D(64, 3, 2, padding='same', use_bias=False),\n",
    "    layers.BatchNormalization(scale=False),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(64, 3, 2, padding='same', use_bias=False),\n",
    "    layers.BatchNormalization(scale=False),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(64, 3, padding='same', use_bias=False),\n",
    "    layers.BatchNormalization(scale=False),\n",
    "    layers.Activation('relu'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(1e-3))],\n",
    "    name='cnn_global_pool')\n",
    "### END SOLUTION\n",
    "\n",
    "train_model(cnn_global_pool, optimizer=optimizers.Adam, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BONUS] A More Complex Architecture: ResNet\n",
    "\n",
    "ResNet is a more modern architecture, introduced by He et al. in 2015 (https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf).\n",
    "\n",
    "It consists of blocks like the following:\n",
    "\n",
    "![ResNet Block](resnet_block.png)\n",
    "\n",
    "There are several variants of it. In the following, we consider ResNetv1, as used for CIFAR-10 in the original ResNet paper (it is simpler compared to the full model used on the much larger ImageNet benchmark).\n",
    "\n",
    "Section 4.2. of the paper describes this architecture as follows: \"*The first layer is 3×3 convolutions. Then we use a stack of 6n layers with 3×3 convolutions on the feature maps of sizes {32, 16, 8} respectively, with 2n layers for each feature map size. The numbers of filters are {16, 32, 64} respectively. The subsampling is performed by convolutions with a stride of 2. The network ends with a global average pooling, a 10-way fully-connected layer, and softmax. [...] When shortcut connections are used, they are connected to the pairs of 3×3 layers (totally 3n shortcuts). On this dataset we use identity shortcuts in all cases.*\"\n",
    "\n",
    "Further, they use L2 regularization. This penalizes weights with large magnitude by adding an additional term to the cost function, besides the cross-entropy. The overall function we optimize becomes.\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{CE} + \\frac{\\lambda}{2} \\sum_{w\\in\\text{weights}} w^2,\n",
    "$$\n",
    "\n",
    "and in this paper $\\lambda=10^{-4}$.\n",
    "\n",
    "Inspect the model creation code and verify that it matches the above description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(num_layers=56):\n",
    "    if (num_layers - 2) % 6 != 0:\n",
    "        raise ValueError('n_layers should be 6n+2 (eg 20, 32, 44, 56)')\n",
    "    n = (num_layers - 2) // 6\n",
    "        \n",
    "    inputs = layers.Input(shape=image_shape)\n",
    "    \n",
    "    # First layer\n",
    "    x = layers.Conv2D(16, 3, use_bias=False, \n",
    "        kernel_regularizer=regularizers.l2(1e-4),\n",
    "        padding='same', kernel_initializer='he_uniform')(inputs)\n",
    "    x = layers.BatchNormalization(scale=False)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # Stack blocks\n",
    "    for i_block in range(n):\n",
    "        x = resnet_block(x, 16, strides=1)\n",
    "        \n",
    "    for i_block in range(n):\n",
    "        x = resnet_block(x, 32, strides=2 if i_block==0 else 1)\n",
    "        \n",
    "    for i_block in range(n):\n",
    "        x = resnet_block(x, 64, strides=2 if i_block==0 else 1)\n",
    "       \n",
    "    # Global pooling and classifier on top\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(\n",
    "        10, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    \n",
    "    return models.Model(inputs=inputs, outputs=outputs, name=f'notresnet{num_layers}')\n",
    "\n",
    "def resnet_block(x, n_channels_out, strides=1):\n",
    "    # First conv\n",
    "    f = layers.Conv2D(n_channels_out, 3, strides, use_bias=False,\n",
    "            kernel_regularizer=regularizers.l2(1e-4),\n",
    "            padding='same', kernel_initializer='he_uniform')(x)\n",
    "    f = layers.BatchNormalization(scale=False)(f)\n",
    "    f = layers.Activation('relu')(f)\n",
    "\n",
    "    # Second conv\n",
    "    f = layers.Conv2D(n_channels_out, 3, use_bias=False,\n",
    "            kernel_regularizer=regularizers.l2(1e-4),\n",
    "            padding='same', kernel_initializer='he_uniform')(f)\n",
    "    f = layers.BatchNormalization(scale=False)(f)\n",
    "    \n",
    "    # The shortcut connection is just the identity.\n",
    "    # If feature channel counts differ between input and output,\n",
    "    # zero padding is used to match the depths.\n",
    "    # This is implemented by a Conv2D with fixed weights.\n",
    "    n_channels_in = x.shape[-1]\n",
    "    if n_channels_in != n_channels_out:\n",
    "        # Fixed weights, np.eye returns a matrix with 1s along the \n",
    "        # main diagonal and zeros elsewhere.\n",
    "        identity_weights = np.eye(n_channels_in, n_channels_out, dtype=np.float32)\n",
    "        layer = layers.Conv2D(\n",
    "            n_channels_out, kernel_size=1, strides=strides, use_bias=False, \n",
    "            kernel_initializer=initializers.Constant(value=identity_weights))\n",
    "        # Not learned! Set trainable to False:\n",
    "        layer.trainable = False\n",
    "        x = layer(x)\n",
    "       \n",
    "    # This is where the ResNet magic happens: the shortcut connection is\n",
    "    # added to the residual.\n",
    "    x = layers.add([x, f])\n",
    "    return layers.Activation('relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BONUS] Learning Rate Decay and Data Augmentation\n",
    "\n",
    "Learning rate decay reduces the learning rate as training progresses. It can be implemented as a Keras callback as a callback as shown below. Fill in the content of `learning_rate_schedule(epoch)`, which returns the learning rate to be used in an epoch (`epoch` is an integer). One possible schedule is the following: $10^{-3}$ for 80 epochs, then drop the learning rate by a factor of 10, train for 40 more epochs and reduce the learning rate by another factor of 10 and train for 30 more epochs. \n",
    "\n",
    "Since ResNet is much larger than the architectures we have looked before, it needs stronger regularization to work well. Data augmentation is one such technique.\n",
    "It perturbs the training examples by e.g. random translation or rotation. Look up the documentation on how to use the `ImageDataGenerator` class of Keras (https://keras.io/preprocessing/image/) and use it in `train_with_lr_decay_and_augmentation`. The ResNet model in the original paper was trained with random translations by $\\pm$ 4 px and random horizontal flipping.\n",
    "\n",
    "If you have a good GPU or lot of time, train ResNet-56 on the CIFAR-10 dataset for about 150 epochs. After 1-2 hours with a GPU, this should result in around 92% accuracy (the state-of-the-art is around 96%). It may also be possible to train this on a CPU in a day or so. If that's too long, you can also train a smaller ResNet, wih `num_layers`=14 or 20, or stop after fewer epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f2042420b7d15963",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def learning_rate_schedule(epoch):\n",
    "    \"\"\"Learning rate is scheduled to be reduced after 80 and 120 epochs.\n",
    "    This function is automatically every epoch as part of callbacks\n",
    "    during training.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    if epoch < 80:\n",
    "        return 1e-3\n",
    "    if epoch < 120:\n",
    "        return 1e-4\n",
    "    return 1e-5\n",
    "    ### END SOLUTION\n",
    "\n",
    "def train_with_lr_decay(model):\n",
    "    model.compile(\n",
    "        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'],\n",
    "        optimizer=optimizers.Adam(lr=1e-3))\n",
    "\n",
    "    # Callback for learning rate adjustment (see below)\n",
    "    lr_scheduler = callbacks.LearningRateScheduler(learning_rate_schedule)\n",
    "\n",
    "    # TensorBoard callback\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    logdir = os.path.join(log_root, f'{model.name}_{timestamp}')\n",
    "    tensorboard_callback = callbacks.TensorBoard(logdir, profile_batch=0)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow()\n",
    "    model.fit(\n",
    "        x_train, y_train, batch_size=128,\n",
    "        validation_data=(x_test, y_test), epochs=150, verbose=1, \n",
    "        callbacks=[lr_scheduler, tensorboard_callback])\n",
    "    \n",
    "def train_with_lr_decay_and_augmentation(model):\n",
    "    model.compile(\n",
    "        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'],\n",
    "        optimizer=optimizers.Adam(lr=1e-3))\n",
    "\n",
    "    # Callback for learning rate adjustment (see below)\n",
    "    lr_scheduler = callbacks.LearningRateScheduler(learning_rate_schedule)\n",
    "\n",
    "    # TensorBoard callback\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    logdir = os.path.join(log_root, f'{model.name}_{timestamp}')\n",
    "    tensorboard_callback = callbacks.TensorBoard(logdir, profile_batch=0)\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    # Data augmentation: flip and shift horizontally/vertically by max 4 pixels\n",
    "    datagen = kerasimage.ImageDataGenerator(\n",
    "        width_shift_range=4, height_shift_range=4,\n",
    "        horizontal_flip=True, fill_mode='constant')\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow()\n",
    "    model.fit_generator(\n",
    "        datagen.flow(x_train, y_train, batch_size=128),\n",
    "        validation_data=(x_test, y_test), epochs=150, verbose=1, \n",
    "        callbacks=[lr_scheduler, tensorboard_callback])\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f2042420b7d15964",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 37s 737us/sample - loss: 1.8533 - accuracy: 0.4796 - val_loss: 2.3070 - val_accuracy: 0.4275\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 22s 448us/sample - loss: 1.3274 - accuracy: 0.6635 - val_loss: 2.0192 - val_accuracy: 0.5017\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 22s 449us/sample - loss: 1.0901 - accuracy: 0.7421 - val_loss: 1.2770 - val_accuracy: 0.6757\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.9546 - accuracy: 0.7813 - val_loss: 1.2796 - val_accuracy: 0.6958\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.8542 - accuracy: 0.8118 - val_loss: 2.2315 - val_accuracy: 0.5514\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.7744 - accuracy: 0.8349 - val_loss: 1.2241 - val_accuracy: 0.6970\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.7175 - accuracy: 0.8523 - val_loss: 1.5641 - val_accuracy: 0.6330\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.6590 - accuracy: 0.8693 - val_loss: 1.1160 - val_accuracy: 0.7533\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.6120 - accuracy: 0.8864 - val_loss: 2.2121 - val_accuracy: 0.5714\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.5708 - accuracy: 0.9000 - val_loss: 1.6297 - val_accuracy: 0.6614\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.5440 - accuracy: 0.9081 - val_loss: 1.5031 - val_accuracy: 0.6717\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.5094 - accuracy: 0.9203 - val_loss: 2.0475 - val_accuracy: 0.6514\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.4813 - accuracy: 0.9302 - val_loss: 1.7817 - val_accuracy: 0.6594\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.4690 - accuracy: 0.9346 - val_loss: 1.8790 - val_accuracy: 0.6533\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.4519 - accuracy: 0.9407 - val_loss: 1.9955 - val_accuracy: 0.6567\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.4391 - accuracy: 0.9463 - val_loss: 1.5306 - val_accuracy: 0.7129\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 22s 449us/sample - loss: 0.4297 - accuracy: 0.9491 - val_loss: 1.6797 - val_accuracy: 0.6991\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.4214 - accuracy: 0.9518 - val_loss: 1.6919 - val_accuracy: 0.6999\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.4124 - accuracy: 0.9552 - val_loss: 1.3871 - val_accuracy: 0.7492\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.4141 - accuracy: 0.9537 - val_loss: 3.4286 - val_accuracy: 0.5100\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.4022 - accuracy: 0.9590 - val_loss: 1.2683 - val_accuracy: 0.7684\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3996 - accuracy: 0.9596 - val_loss: 1.4148 - val_accuracy: 0.7464\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.4021 - accuracy: 0.9582 - val_loss: 2.1715 - val_accuracy: 0.6327\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3988 - accuracy: 0.9594 - val_loss: 1.6366 - val_accuracy: 0.7214\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3851 - accuracy: 0.9648 - val_loss: 1.5945 - val_accuracy: 0.7091\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3841 - accuracy: 0.9645 - val_loss: 2.1010 - val_accuracy: 0.6639\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3868 - accuracy: 0.9633 - val_loss: 1.3500 - val_accuracy: 0.7507\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3777 - accuracy: 0.9662 - val_loss: 2.3496 - val_accuracy: 0.6408\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3726 - accuracy: 0.9672 - val_loss: 1.3830 - val_accuracy: 0.7523\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3790 - accuracy: 0.9656 - val_loss: 1.4266 - val_accuracy: 0.7420\n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3709 - accuracy: 0.9677 - val_loss: 1.3005 - val_accuracy: 0.7650\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3646 - accuracy: 0.9693 - val_loss: 2.0075 - val_accuracy: 0.6768\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3637 - accuracy: 0.9692 - val_loss: 1.7312 - val_accuracy: 0.7023\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3789 - accuracy: 0.9644 - val_loss: 2.0193 - val_accuracy: 0.6896\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3579 - accuracy: 0.9718 - val_loss: 1.3206 - val_accuracy: 0.7756\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3591 - accuracy: 0.9693 - val_loss: 1.5727 - val_accuracy: 0.7346\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 22s 449us/sample - loss: 0.3690 - accuracy: 0.9665 - val_loss: 1.5928 - val_accuracy: 0.7256\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3599 - accuracy: 0.9698 - val_loss: 2.7457 - val_accuracy: 0.6214\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.3524 - accuracy: 0.9716 - val_loss: 1.7114 - val_accuracy: 0.7212\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3564 - accuracy: 0.9706 - val_loss: 1.7307 - val_accuracy: 0.7151\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.3595 - accuracy: 0.9689 - val_loss: 1.9020 - val_accuracy: 0.6903\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3500 - accuracy: 0.9721 - val_loss: 1.3939 - val_accuracy: 0.7497\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.3452 - accuracy: 0.9733 - val_loss: 1.5294 - val_accuracy: 0.7329\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3527 - accuracy: 0.9699 - val_loss: 2.0283 - val_accuracy: 0.7064\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.3536 - accuracy: 0.9703 - val_loss: 1.8006 - val_accuracy: 0.7113\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3444 - accuracy: 0.9729 - val_loss: 1.9191 - val_accuracy: 0.6877\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3419 - accuracy: 0.9737 - val_loss: 1.4975 - val_accuracy: 0.7601\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3471 - accuracy: 0.9716 - val_loss: 1.5800 - val_accuracy: 0.7482\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3372 - accuracy: 0.9749 - val_loss: 1.7301 - val_accuracy: 0.7005\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3386 - accuracy: 0.9730 - val_loss: 1.4538 - val_accuracy: 0.7727\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3451 - accuracy: 0.9713 - val_loss: 1.7804 - val_accuracy: 0.7160\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3356 - accuracy: 0.9749 - val_loss: 2.5262 - val_accuracy: 0.6379\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3375 - accuracy: 0.9736 - val_loss: 1.2886 - val_accuracy: 0.7603\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3403 - accuracy: 0.9732 - val_loss: 1.2598 - val_accuracy: 0.7772\n",
      "Epoch 55/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3362 - accuracy: 0.9733 - val_loss: 2.1312 - val_accuracy: 0.6985\n",
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.3314 - accuracy: 0.9761 - val_loss: 1.6059 - val_accuracy: 0.7331\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3245 - accuracy: 0.9768 - val_loss: 1.7657 - val_accuracy: 0.7092\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3429 - accuracy: 0.9716 - val_loss: 1.5747 - val_accuracy: 0.7282\n",
      "Epoch 59/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3276 - accuracy: 0.9766 - val_loss: 2.0253 - val_accuracy: 0.6914\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.3297 - accuracy: 0.9750 - val_loss: 1.4807 - val_accuracy: 0.7512\n",
      "Epoch 61/150\n",
      "50000/50000 [==============================] - 23s 468us/sample - loss: 0.3297 - accuracy: 0.9739 - val_loss: 2.0409 - val_accuracy: 0.7026\n",
      "Epoch 62/150\n",
      "50000/50000 [==============================] - 24s 470us/sample - loss: 0.3319 - accuracy: 0.9743 - val_loss: 1.8593 - val_accuracy: 0.7015\n",
      "Epoch 63/150\n",
      "50000/50000 [==============================] - 24s 470us/sample - loss: 0.3255 - accuracy: 0.9760 - val_loss: 2.0328 - val_accuracy: 0.6846\n",
      "Epoch 64/150\n",
      "50000/50000 [==============================] - 23s 459us/sample - loss: 0.3294 - accuracy: 0.9750 - val_loss: 1.3305 - val_accuracy: 0.7653\n",
      "Epoch 65/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3261 - accuracy: 0.9755 - val_loss: 1.9658 - val_accuracy: 0.7134\n",
      "Epoch 66/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3216 - accuracy: 0.9769 - val_loss: 1.5524 - val_accuracy: 0.7385\n",
      "Epoch 67/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3298 - accuracy: 0.9736 - val_loss: 1.8103 - val_accuracy: 0.7345\n",
      "Epoch 68/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3206 - accuracy: 0.9778 - val_loss: 1.8913 - val_accuracy: 0.7130\n",
      "Epoch 69/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.3273 - accuracy: 0.9746 - val_loss: 1.7955 - val_accuracy: 0.7392\n",
      "Epoch 70/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.3211 - accuracy: 0.9763 - val_loss: 1.5198 - val_accuracy: 0.7348\n",
      "Epoch 71/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3206 - accuracy: 0.9769 - val_loss: 1.5303 - val_accuracy: 0.7414\n",
      "Epoch 72/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3101 - accuracy: 0.9797 - val_loss: 2.6425 - val_accuracy: 0.6454\n",
      "Epoch 73/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3231 - accuracy: 0.9743 - val_loss: 1.1761 - val_accuracy: 0.7767\n",
      "Epoch 74/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3190 - accuracy: 0.9775 - val_loss: 1.3289 - val_accuracy: 0.7721\n",
      "Epoch 75/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3229 - accuracy: 0.9748 - val_loss: 1.3606 - val_accuracy: 0.7677\n",
      "Epoch 76/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3201 - accuracy: 0.9761 - val_loss: 1.2124 - val_accuracy: 0.7803\n",
      "Epoch 77/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.3093 - accuracy: 0.9786 - val_loss: 1.6364 - val_accuracy: 0.7265\n",
      "Epoch 78/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.3180 - accuracy: 0.9761 - val_loss: 1.6940 - val_accuracy: 0.7185\n",
      "Epoch 79/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.3169 - accuracy: 0.9763 - val_loss: 1.3448 - val_accuracy: 0.7798\n",
      "Epoch 80/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.3182 - accuracy: 0.9759 - val_loss: 1.3547 - val_accuracy: 0.7682\n",
      "Epoch 81/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.2739 - accuracy: 0.9930 - val_loss: 0.9356 - val_accuracy: 0.8331\n",
      "Epoch 82/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.2531 - accuracy: 0.9992 - val_loss: 0.9426 - val_accuracy: 0.8358\n",
      "Epoch 83/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.2464 - accuracy: 0.9998 - val_loss: 0.9486 - val_accuracy: 0.8380\n",
      "Epoch 84/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.2409 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.8363\n",
      "Epoch 85/150\n",
      "50000/50000 [==============================] - 22s 450us/sample - loss: 0.2352 - accuracy: 1.0000 - val_loss: 0.9922 - val_accuracy: 0.8380\n",
      "Epoch 86/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.2290 - accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 0.8391\n",
      "Epoch 87/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.2222 - accuracy: 1.0000 - val_loss: 1.0773 - val_accuracy: 0.8367\n",
      "Epoch 88/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.8383\n",
      "Epoch 89/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.2065 - accuracy: 0.9999 - val_loss: 1.1112 - val_accuracy: 0.8397\n",
      "Epoch 90/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.1976 - accuracy: 0.9999 - val_loss: 1.1158 - val_accuracy: 0.8388\n",
      "Epoch 91/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1891 - accuracy: 0.9996 - val_loss: 1.2095 - val_accuracy: 0.8224\n",
      "Epoch 92/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1826 - accuracy: 0.9995 - val_loss: 1.1262 - val_accuracy: 0.8370\n",
      "Epoch 93/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1745 - accuracy: 1.0000 - val_loss: 1.1289 - val_accuracy: 0.8352\n",
      "Epoch 94/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1681 - accuracy: 0.9997 - val_loss: 1.1665 - val_accuracy: 0.8280\n",
      "Epoch 95/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1613 - accuracy: 0.9999 - val_loss: 1.1730 - val_accuracy: 0.8324\n",
      "Epoch 96/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.1548 - accuracy: 0.9999 - val_loss: 1.1941 - val_accuracy: 0.8312\n",
      "Epoch 97/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1517 - accuracy: 0.9989 - val_loss: 1.2233 - val_accuracy: 0.8290\n",
      "Epoch 98/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1467 - accuracy: 0.9996 - val_loss: 1.1193 - val_accuracy: 0.8341\n",
      "Epoch 99/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1421 - accuracy: 0.9999 - val_loss: 1.1101 - val_accuracy: 0.8345\n",
      "Epoch 100/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.1378 - accuracy: 0.9999 - val_loss: 1.1397 - val_accuracy: 0.8351\n",
      "Epoch 101/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.1334 - accuracy: 1.0000 - val_loss: 1.1428 - val_accuracy: 0.8339\n",
      "Epoch 102/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.1297 - accuracy: 0.9997 - val_loss: 1.2030 - val_accuracy: 0.8236\n",
      "Epoch 103/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.1287 - accuracy: 0.9989 - val_loss: 1.2837 - val_accuracy: 0.8091\n",
      "Epoch 104/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1245 - accuracy: 0.9995 - val_loss: 1.1237 - val_accuracy: 0.8312\n",
      "Epoch 105/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1206 - accuracy: 0.9999 - val_loss: 1.1242 - val_accuracy: 0.8347\n",
      "Epoch 106/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1172 - accuracy: 1.0000 - val_loss: 1.1157 - val_accuracy: 0.8381\n",
      "Epoch 107/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.1138 - accuracy: 0.9999 - val_loss: 1.1516 - val_accuracy: 0.8340\n",
      "Epoch 108/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1114 - accuracy: 0.9995 - val_loss: 1.4781 - val_accuracy: 0.7978\n",
      "Epoch 109/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1149 - accuracy: 0.9977 - val_loss: 1.1139 - val_accuracy: 0.8330\n",
      "Epoch 110/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1080 - accuracy: 0.9997 - val_loss: 1.1225 - val_accuracy: 0.8377\n",
      "Epoch 111/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.1058 - accuracy: 0.9998 - val_loss: 1.1212 - val_accuracy: 0.8366\n",
      "Epoch 112/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.1033 - accuracy: 1.0000 - val_loss: 1.1615 - val_accuracy: 0.8303\n",
      "Epoch 113/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.1010 - accuracy: 0.9999 - val_loss: 1.1593 - val_accuracy: 0.8331\n",
      "Epoch 114/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.0990 - accuracy: 0.9998 - val_loss: 1.1664 - val_accuracy: 0.8259\n",
      "Epoch 115/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.1041 - accuracy: 0.9976 - val_loss: 1.1847 - val_accuracy: 0.8158\n",
      "Epoch 116/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0979 - accuracy: 0.9994 - val_loss: 1.1029 - val_accuracy: 0.8338\n",
      "Epoch 117/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0950 - accuracy: 0.9999 - val_loss: 1.1367 - val_accuracy: 0.8324\n",
      "Epoch 118/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.0934 - accuracy: 0.9998 - val_loss: 1.1224 - val_accuracy: 0.8359\n",
      "Epoch 119/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0917 - accuracy: 0.9999 - val_loss: 1.1192 - val_accuracy: 0.8317\n",
      "Epoch 120/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0919 - accuracy: 0.9993 - val_loss: 1.3514 - val_accuracy: 0.8076\n",
      "Epoch 121/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0905 - accuracy: 0.9996 - val_loss: 1.1003 - val_accuracy: 0.8333\n",
      "Epoch 122/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0891 - accuracy: 1.0000 - val_loss: 1.0936 - val_accuracy: 0.8343\n",
      "Epoch 123/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0887 - accuracy: 1.0000 - val_loss: 1.0947 - val_accuracy: 0.8363\n",
      "Epoch 124/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0884 - accuracy: 1.0000 - val_loss: 1.0910 - val_accuracy: 0.8359\n",
      "Epoch 125/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0881 - accuracy: 1.0000 - val_loss: 1.0938 - val_accuracy: 0.8363\n",
      "Epoch 126/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.0878 - accuracy: 1.0000 - val_loss: 1.0938 - val_accuracy: 0.8358\n",
      "Epoch 127/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.8365\n",
      "Epoch 128/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0869 - accuracy: 1.0000 - val_loss: 1.0947 - val_accuracy: 0.8367\n",
      "Epoch 129/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0864 - accuracy: 1.0000 - val_loss: 1.0969 - val_accuracy: 0.8375\n",
      "Epoch 130/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0858 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.8363\n",
      "Epoch 131/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0852 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.8369\n",
      "Epoch 132/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.0845 - accuracy: 1.0000 - val_loss: 1.0979 - val_accuracy: 0.8377\n",
      "Epoch 133/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.0838 - accuracy: 1.0000 - val_loss: 1.0978 - val_accuracy: 0.8377\n",
      "Epoch 134/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.0830 - accuracy: 1.0000 - val_loss: 1.0948 - val_accuracy: 0.8378\n",
      "Epoch 135/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0821 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.8388\n",
      "Epoch 136/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0812 - accuracy: 1.0000 - val_loss: 1.0975 - val_accuracy: 0.8381\n",
      "Epoch 137/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0801 - accuracy: 1.0000 - val_loss: 1.0989 - val_accuracy: 0.8380\n",
      "Epoch 138/150\n",
      "50000/50000 [==============================] - 23s 452us/sample - loss: 0.0790 - accuracy: 1.0000 - val_loss: 1.0991 - val_accuracy: 0.8371\n",
      "Epoch 139/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0778 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.8384\n",
      "Epoch 140/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0766 - accuracy: 1.0000 - val_loss: 1.1008 - val_accuracy: 0.8359\n",
      "Epoch 141/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0753 - accuracy: 1.0000 - val_loss: 1.1039 - val_accuracy: 0.8366\n",
      "Epoch 142/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0741 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.8367\n",
      "Epoch 143/150\n",
      "50000/50000 [==============================] - 23s 450us/sample - loss: 0.0729 - accuracy: 1.0000 - val_loss: 1.1020 - val_accuracy: 0.8368\n",
      "Epoch 144/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0717 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.8389\n",
      "Epoch 145/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0705 - accuracy: 1.0000 - val_loss: 1.0989 - val_accuracy: 0.8384\n",
      "Epoch 146/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0694 - accuracy: 1.0000 - val_loss: 1.1010 - val_accuracy: 0.8372\n",
      "Epoch 147/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0684 - accuracy: 1.0000 - val_loss: 1.0984 - val_accuracy: 0.8376\n",
      "Epoch 148/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0676 - accuracy: 1.0000 - val_loss: 1.0894 - val_accuracy: 0.8382\n",
      "Epoch 149/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0667 - accuracy: 1.0000 - val_loss: 1.0860 - val_accuracy: 0.8407\n",
      "Epoch 150/150\n",
      "50000/50000 [==============================] - 23s 451us/sample - loss: 0.0658 - accuracy: 1.0000 - val_loss: 1.0869 - val_accuracy: 0.8392\n"
     ]
    }
   ],
   "source": [
    "resnet56 = resnet(56)\n",
    "train_with_lr_decay(resnet56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "391/391 [==============================] - 105s 268ms/step - loss: 2.5315 - accuracy: 0.1893 - val_loss: 20.3600 - val_accuracy: 0.1673\n",
      "Epoch 2/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 2.1871 - accuracy: 0.3013 - val_loss: 2.3645 - val_accuracy: 0.2917\n",
      "Epoch 3/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 2.0245 - accuracy: 0.3481 - val_loss: 2.6100 - val_accuracy: 0.2659\n",
      "Epoch 4/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.9312 - accuracy: 0.3732 - val_loss: 1.8635 - val_accuracy: 0.4033\n",
      "Epoch 5/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 1.8459 - accuracy: 0.3985 - val_loss: 1.9316 - val_accuracy: 0.3979\n",
      "Epoch 6/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.7684 - accuracy: 0.4245 - val_loss: 2.0513 - val_accuracy: 0.3928\n",
      "Epoch 7/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.6839 - accuracy: 0.4563 - val_loss: 1.6558 - val_accuracy: 0.4701\n",
      "Epoch 8/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.6208 - accuracy: 0.4802 - val_loss: 1.6262 - val_accuracy: 0.4632\n",
      "Epoch 9/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.5559 - accuracy: 0.5050 - val_loss: 1.7561 - val_accuracy: 0.4332\n",
      "Epoch 10/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.5014 - accuracy: 0.5231 - val_loss: 1.7209 - val_accuracy: 0.4470\n",
      "Epoch 11/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.4509 - accuracy: 0.5424 - val_loss: 1.9681 - val_accuracy: 0.4201\n",
      "Epoch 12/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.3996 - accuracy: 0.5585 - val_loss: 1.5076 - val_accuracy: 0.5102\n",
      "Epoch 13/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 1.3562 - accuracy: 0.5733 - val_loss: 1.7875 - val_accuracy: 0.4769\n",
      "Epoch 14/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.3113 - accuracy: 0.5913 - val_loss: 1.5164 - val_accuracy: 0.5248\n",
      "Epoch 15/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.2716 - accuracy: 0.6060 - val_loss: 1.7391 - val_accuracy: 0.4682\n",
      "Epoch 16/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.2241 - accuracy: 0.6224 - val_loss: 1.8209 - val_accuracy: 0.5078\n",
      "Epoch 17/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.1874 - accuracy: 0.6349 - val_loss: 2.1300 - val_accuracy: 0.4653\n",
      "Epoch 18/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.1515 - accuracy: 0.6485 - val_loss: 1.6459 - val_accuracy: 0.4931\n",
      "Epoch 19/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.1206 - accuracy: 0.6599 - val_loss: 1.4162 - val_accuracy: 0.5807\n",
      "Epoch 20/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.0859 - accuracy: 0.6718 - val_loss: 1.3120 - val_accuracy: 0.6223\n",
      "Epoch 21/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.0672 - accuracy: 0.6821 - val_loss: 1.5834 - val_accuracy: 0.5498\n",
      "Epoch 22/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.0326 - accuracy: 0.6957 - val_loss: 1.2132 - val_accuracy: 0.6341\n",
      "Epoch 23/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 1.0099 - accuracy: 0.7044 - val_loss: 1.6114 - val_accuracy: 0.5491\n",
      "Epoch 24/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.9765 - accuracy: 0.7197 - val_loss: 1.0689 - val_accuracy: 0.6866\n",
      "Epoch 25/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.9608 - accuracy: 0.7256 - val_loss: 1.0783 - val_accuracy: 0.6796\n",
      "Epoch 26/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.9383 - accuracy: 0.7333 - val_loss: 1.0963 - val_accuracy: 0.68216 - \n",
      "Epoch 27/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.9106 - accuracy: 0.7467 - val_loss: 1.4940 - val_accuracy: 0.6216\n",
      "Epoch 28/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.8910 - accuracy: 0.7522 - val_loss: 1.2104 - val_accuracy: 0.6409\n",
      "Epoch 29/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.8834 - accuracy: 0.7571 - val_loss: 1.3265 - val_accuracy: 0.6129\n",
      "Epoch 30/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.8646 - accuracy: 0.7631 - val_loss: 1.1856 - val_accuracy: 0.6714\n",
      "Epoch 31/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.8465 - accuracy: 0.7703 - val_loss: 1.4972 - val_accuracy: 0.6271\n",
      "Epoch 32/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.8410 - accuracy: 0.7705 - val_loss: 1.5440 - val_accuracy: 0.6051\n",
      "Epoch 33/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.8309 - accuracy: 0.7762 - val_loss: 1.8725 - val_accuracy: 0.5769\n",
      "Epoch 34/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.8138 - accuracy: 0.7845 - val_loss: 1.3271 - val_accuracy: 0.6201\n",
      "Epoch 35/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.8024 - accuracy: 0.7860 - val_loss: 1.8969 - val_accuracy: 0.4378\n",
      "Epoch 36/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7854 - accuracy: 0.7926 - val_loss: 1.0291 - val_accuracy: 0.7105\n",
      "Epoch 37/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7830 - accuracy: 0.7933 - val_loss: 0.9503 - val_accuracy: 0.7475\n",
      "Epoch 38/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.7642 - accuracy: 0.7998 - val_loss: 1.2754 - val_accuracy: 0.6481\n",
      "Epoch 39/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7636 - accuracy: 0.8001 - val_loss: 0.9737 - val_accuracy: 0.7409\n",
      "Epoch 40/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7580 - accuracy: 0.8011 - val_loss: 1.0500 - val_accuracy: 0.7153\n",
      "Epoch 41/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7471 - accuracy: 0.8067 - val_loss: 0.9826 - val_accuracy: 0.7359\n",
      "Epoch 42/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7430 - accuracy: 0.8099 - val_loss: 1.4589 - val_accuracy: 0.5686\n",
      "Epoch 43/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7347 - accuracy: 0.8109 - val_loss: 1.2278 - val_accuracy: 0.6539\n",
      "Epoch 44/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7275 - accuracy: 0.8114 - val_loss: 2.1318 - val_accuracy: 0.5160\n",
      "Epoch 45/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7214 - accuracy: 0.8177 - val_loss: 1.0644 - val_accuracy: 0.7064\n",
      "Epoch 46/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7137 - accuracy: 0.8202 - val_loss: 1.1800 - val_accuracy: 0.7063\n",
      "Epoch 47/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7083 - accuracy: 0.8210 - val_loss: 1.2355 - val_accuracy: 0.6822\n",
      "Epoch 48/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7023 - accuracy: 0.8237 - val_loss: 1.1211 - val_accuracy: 0.6848\n",
      "Epoch 49/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7003 - accuracy: 0.8235 - val_loss: 3.4809 - val_accuracy: 0.4356\n",
      "Epoch 50/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6942 - accuracy: 0.8254 - val_loss: 5.8349 - val_accuracy: 0.4644\n",
      "Epoch 51/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.6890 - accuracy: 0.8280 - val_loss: 1.7629 - val_accuracy: 0.5331\n",
      "Epoch 52/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6852 - accuracy: 0.8302 - val_loss: 0.9154 - val_accuracy: 0.7719\n",
      "Epoch 53/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6786 - accuracy: 0.8304 - val_loss: 3.7007 - val_accuracy: 0.4950\n",
      "Epoch 54/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6728 - accuracy: 0.8335 - val_loss: 1.7800 - val_accuracy: 0.4939\n",
      "Epoch 55/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6666 - accuracy: 0.8352 - val_loss: 0.9699 - val_accuracy: 0.7482\n",
      "Epoch 56/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6658 - accuracy: 0.8377 - val_loss: 1.1463 - val_accuracy: 0.6786\n",
      "Epoch 57/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6588 - accuracy: 0.8396 - val_loss: 2.8234 - val_accuracy: 0.5077\n",
      "Epoch 58/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6591 - accuracy: 0.8379 - val_loss: 0.9101 - val_accuracy: 0.7726\n",
      "Epoch 59/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6552 - accuracy: 0.8393 - val_loss: 1.3135 - val_accuracy: 0.5858\n",
      "Epoch 60/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.6505 - accuracy: 0.8437 - val_loss: 1.2352 - val_accuracy: 0.7083\n",
      "Epoch 61/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6460 - accuracy: 0.8434 - val_loss: 2.3456 - val_accuracy: 0.4254\n",
      "Epoch 62/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6447 - accuracy: 0.8434 - val_loss: 1.2471 - val_accuracy: 0.6942\n",
      "Epoch 63/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6399 - accuracy: 0.8474 - val_loss: 1.0970 - val_accuracy: 0.7154\n",
      "Epoch 64/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6380 - accuracy: 0.8473 - val_loss: 0.9063 - val_accuracy: 0.7578\n",
      "Epoch 65/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6309 - accuracy: 0.8487 - val_loss: 1.0401 - val_accuracy: 0.7214\n",
      "Epoch 66/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6256 - accuracy: 0.8510 - val_loss: 2.0400 - val_accuracy: 0.5661\n",
      "Epoch 67/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.6287 - accuracy: 0.8505 - val_loss: 1.2080 - val_accuracy: 0.6698\n",
      "Epoch 68/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6233 - accuracy: 0.8517 - val_loss: 150.4951 - val_accuracy: 0.1323\n",
      "Epoch 69/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6262 - accuracy: 0.8512 - val_loss: 1.4570 - val_accuracy: 0.5669\n",
      "Epoch 70/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6176 - accuracy: 0.8551 - val_loss: 2.6088 - val_accuracy: 0.4775\n",
      "Epoch 71/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6139 - accuracy: 0.8568 - val_loss: 1.1985 - val_accuracy: 0.6739\n",
      "Epoch 72/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6126 - accuracy: 0.8553 - val_loss: 1.0310 - val_accuracy: 0.7382\n",
      "Epoch 73/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6085 - accuracy: 0.8568 - val_loss: 1.0416 - val_accuracy: 0.7362\n",
      "Epoch 74/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6111 - accuracy: 0.8541 - val_loss: 1.6854 - val_accuracy: 0.6666\n",
      "Epoch 75/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6020 - accuracy: 0.8604 - val_loss: 1.3543 - val_accuracy: 0.6833\n",
      "Epoch 76/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6052 - accuracy: 0.8576 - val_loss: 0.9037 - val_accuracy: 0.7669\n",
      "Epoch 77/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6012 - accuracy: 0.8599 - val_loss: 1.5568 - val_accuracy: 0.6538\n",
      "Epoch 78/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.5952 - accuracy: 0.8618 - val_loss: 2.2525 - val_accuracy: 0.3597\n",
      "Epoch 79/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.5958 - accuracy: 0.8612 - val_loss: 1.4314 - val_accuracy: 0.6297\n",
      "Epoch 80/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6001 - accuracy: 0.8605 - val_loss: 1.2219 - val_accuracy: 0.7216\n",
      "Epoch 81/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4974 - accuracy: 0.8952 - val_loss: 0.7756 - val_accuracy: 0.8059\n",
      "Epoch 82/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4606 - accuracy: 0.9071 - val_loss: 0.7059 - val_accuracy: 0.8287\n",
      "Epoch 83/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4470 - accuracy: 0.9104 - val_loss: 0.7144 - val_accuracy: 0.8231\n",
      "Epoch 84/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4358 - accuracy: 0.9147 - val_loss: 0.6511 - val_accuracy: 0.8437\n",
      "Epoch 85/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4300 - accuracy: 0.9156 - val_loss: 0.6926 - val_accuracy: 0.8293\n",
      "Epoch 86/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4217 - accuracy: 0.9198 - val_loss: 0.7285 - val_accuracy: 0.8206\n",
      "Epoch 87/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4188 - accuracy: 0.9190 - val_loss: 0.6239 - val_accuracy: 0.8537\n",
      "Epoch 88/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4143 - accuracy: 0.9195 - val_loss: 0.6282 - val_accuracy: 0.8526\n",
      "Epoch 89/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4113 - accuracy: 0.9211 - val_loss: 0.6639 - val_accuracy: 0.8439\n",
      "Epoch 90/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4036 - accuracy: 0.9219 - val_loss: 0.6387 - val_accuracy: 0.8490\n",
      "Epoch 91/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3993 - accuracy: 0.9236 - val_loss: 0.6253 - val_accuracy: 0.8557\n",
      "Epoch 92/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3986 - accuracy: 0.9242 - val_loss: 0.6363 - val_accuracy: 0.8572\n",
      "Epoch 93/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3949 - accuracy: 0.9244 - val_loss: 0.6279 - val_accuracy: 0.8513\n",
      "Epoch 94/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3890 - accuracy: 0.9259 - val_loss: 0.6084 - val_accuracy: 0.8587\n",
      "Epoch 95/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3833 - accuracy: 0.9284 - val_loss: 0.6519 - val_accuracy: 0.8473\n",
      "Epoch 96/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3838 - accuracy: 0.9265 - val_loss: 0.6242 - val_accuracy: 0.8538\n",
      "Epoch 97/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3800 - accuracy: 0.9290 - val_loss: 0.6517 - val_accuracy: 0.8489\n",
      "Epoch 98/150\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.3719 - accuracy: 0.9310 - val_loss: 0.6324 - val_accuracy: 0.8544\n",
      "Epoch 99/150\n",
      "391/391 [==============================] - 28s 73ms/step - loss: 0.3734 - accuracy: 0.9295 - val_loss: 0.6261 - val_accuracy: 0.8558\n",
      "Epoch 100/150\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 0.3685 - accuracy: 0.9317 - val_loss: 0.6477 - val_accuracy: 0.8541\n",
      "Epoch 101/150\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.3689 - accuracy: 0.9310 - val_loss: 0.6545 - val_accuracy: 0.8485\n",
      "Epoch 102/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3646 - accuracy: 0.9320 - val_loss: 0.6257 - val_accuracy: 0.8585\n",
      "Epoch 103/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3634 - accuracy: 0.9319 - val_loss: 0.6410 - val_accuracy: 0.8602\n",
      "Epoch 104/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3588 - accuracy: 0.9347 - val_loss: 0.6298 - val_accuracy: 0.8579\n",
      "Epoch 105/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3580 - accuracy: 0.9342 - val_loss: 0.6404 - val_accuracy: 0.8551\n",
      "Epoch 106/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3533 - accuracy: 0.9368 - val_loss: 0.6318 - val_accuracy: 0.8571\n",
      "Epoch 107/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3546 - accuracy: 0.9353 - val_loss: 0.6369 - val_accuracy: 0.8603\n",
      "Epoch 108/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3508 - accuracy: 0.9358 - val_loss: 0.6552 - val_accuracy: 0.8479\n",
      "Epoch 109/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3488 - accuracy: 0.9376 - val_loss: 0.6300 - val_accuracy: 0.8560\n",
      "Epoch 110/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3473 - accuracy: 0.9368 - val_loss: 0.6381 - val_accuracy: 0.8537\n",
      "Epoch 111/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3489 - accuracy: 0.9372 - val_loss: 0.6556 - val_accuracy: 0.8548\n",
      "Epoch 112/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3421 - accuracy: 0.9387 - val_loss: 0.6507 - val_accuracy: 0.8530\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3394 - accuracy: 0.9395 - val_loss: 0.6502 - val_accuracy: 0.8581\n",
      "Epoch 114/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3396 - accuracy: 0.9382 - val_loss: 0.6499 - val_accuracy: 0.8557\n",
      "Epoch 115/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3370 - accuracy: 0.9391 - val_loss: 0.6617 - val_accuracy: 0.8533\n",
      "Epoch 116/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3354 - accuracy: 0.9410 - val_loss: 0.7013 - val_accuracy: 0.8433\n",
      "Epoch 117/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3331 - accuracy: 0.9410 - val_loss: 0.6908 - val_accuracy: 0.8461\n",
      "Epoch 118/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3333 - accuracy: 0.9409 - val_loss: 0.6988 - val_accuracy: 0.8433\n",
      "Epoch 119/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3308 - accuracy: 0.9408 - val_loss: 0.6582 - val_accuracy: 0.8586\n",
      "Epoch 120/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3263 - accuracy: 0.9419 - val_loss: 0.6925 - val_accuracy: 0.8509\n",
      "Epoch 121/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3154 - accuracy: 0.9467 - val_loss: 0.6374 - val_accuracy: 0.8610\n",
      "Epoch 122/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3112 - accuracy: 0.9476 - val_loss: 0.6362 - val_accuracy: 0.8601\n",
      "Epoch 123/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3097 - accuracy: 0.9491 - val_loss: 0.6351 - val_accuracy: 0.8616\n",
      "Epoch 124/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3104 - accuracy: 0.9490 - val_loss: 0.6336 - val_accuracy: 0.8618\n",
      "Epoch 125/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3068 - accuracy: 0.9505 - val_loss: 0.6352 - val_accuracy: 0.8621\n",
      "Epoch 126/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3057 - accuracy: 0.9493 - val_loss: 0.6385 - val_accuracy: 0.8608\n",
      "Epoch 127/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3035 - accuracy: 0.9512 - val_loss: 0.6383 - val_accuracy: 0.8610\n",
      "Epoch 128/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3097 - accuracy: 0.9481 - val_loss: 0.6412 - val_accuracy: 0.8615\n",
      "Epoch 129/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3063 - accuracy: 0.9491 - val_loss: 0.6395 - val_accuracy: 0.8613\n",
      "Epoch 130/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3059 - accuracy: 0.9503 - val_loss: 0.6384 - val_accuracy: 0.86120s - loss:\n",
      "Epoch 131/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3040 - accuracy: 0.9509 - val_loss: 0.6457 - val_accuracy: 0.8602\n",
      "Epoch 132/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3048 - accuracy: 0.9498 - val_loss: 0.6422 - val_accuracy: 0.8632\n",
      "Epoch 133/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3006 - accuracy: 0.9521 - val_loss: 0.6420 - val_accuracy: 0.8616\n",
      "Epoch 134/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3027 - accuracy: 0.9511 - val_loss: 0.6410 - val_accuracy: 0.8625\n",
      "Epoch 135/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3013 - accuracy: 0.9510 - val_loss: 0.6426 - val_accuracy: 0.8617\n",
      "Epoch 136/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3009 - accuracy: 0.9513 - val_loss: 0.6425 - val_accuracy: 0.8606\n",
      "Epoch 137/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3012 - accuracy: 0.9506 - val_loss: 0.6441 - val_accuracy: 0.8604\n",
      "Epoch 138/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3007 - accuracy: 0.9508 - val_loss: 0.6447 - val_accuracy: 0.8604\n",
      "Epoch 139/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.2997 - accuracy: 0.9525 - val_loss: 0.6456 - val_accuracy: 0.8611\n",
      "Epoch 140/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3008 - accuracy: 0.9528 - val_loss: 0.6442 - val_accuracy: 0.8612\n",
      "Epoch 141/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3004 - accuracy: 0.9516 - val_loss: 0.6454 - val_accuracy: 0.8624\n",
      "Epoch 142/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.2985 - accuracy: 0.9518 - val_loss: 0.6419 - val_accuracy: 0.8615\n",
      "Epoch 143/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3005 - accuracy: 0.9516 - val_loss: 0.6477 - val_accuracy: 0.8613\n",
      "Epoch 144/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.2972 - accuracy: 0.9535 - val_loss: 0.6457 - val_accuracy: 0.8611\n",
      "Epoch 145/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3023 - accuracy: 0.9509 - val_loss: 0.6454 - val_accuracy: 0.8608\n",
      "Epoch 146/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3013 - accuracy: 0.9521 - val_loss: 0.6454 - val_accuracy: 0.8618\n",
      "Epoch 147/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.2971 - accuracy: 0.9536 - val_loss: 0.6462 - val_accuracy: 0.8613\n",
      "Epoch 148/150\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.2978 - accuracy: 0.9527 - val_loss: 0.6463 - val_accuracy: 0.8622\n",
      "Epoch 149/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.2989 - accuracy: 0.9520 - val_loss: 0.6463 - val_accuracy: 0.8618\n",
      "Epoch 150/150\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.2981 - accuracy: 0.9524 - val_loss: 0.6515 - val_accuracy: 0.8629\n"
     ]
    }
   ],
   "source": [
    "resnet56 = resnet(56)\n",
    "train_with_lr_decay_and_augmentation(resnet56)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
